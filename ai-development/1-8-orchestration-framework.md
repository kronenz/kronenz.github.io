---
layout: default
title: "1-8: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ í”„ë ˆì„ì›Œí¬ ì„ íƒ - CrewAI vs AutoGen vs LangGraph ë¹„êµ ë¶„ì„"
description: "ì—ì´ì „í‹± SaaS ì¡°ì§ ê°€ì´ë“œ"
series: "series-1"
order: 10
---

# 1-8: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ í”„ë ˆì„ì›Œí¬ ì„ íƒ - CrewAI vs AutoGen vs LangGraph ë¹„êµ ë¶„ì„

## ğŸ“‹ ê°œìš”

ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ íš¨ê³¼ì ìœ¼ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•´ì„œëŠ” ì ì ˆí•œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ í”„ë ˆì„ì›Œí¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ ê°€ì´ë“œì—ì„œëŠ” CrewAI, AutoGen, LangGraphì˜ íŠ¹ì§•ì„ ë¹„êµí•˜ê³  í”„ë¡œì íŠ¸ì— ë§ëŠ” ìµœì ì˜ ì„ íƒì„ í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.

## ğŸ¯ í•™ìŠµ ëª©í‘œ

ì´ ê°€ì´ë“œë¥¼ ì™„ë£Œí•˜ë©´ ë‹¤ìŒì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

1. **ì£¼ìš” ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ í”„ë ˆì„ì›Œí¬ì˜ íŠ¹ì§• ì´í•´**
2. **í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” í”„ë ˆì„ì›Œí¬ ì„ íƒ ëŠ¥ë ¥**
3. **ê° í”„ë ˆì„ì›Œí¬ì˜ ì¥ë‹¨ì ê³¼ í™œìš© ì‹œë‚˜ë¦¬ì˜¤ íŒŒì•…**
4. **ì‹¤ì œ í”„ë¡œì íŠ¸ì— í”„ë ˆì„ì›Œí¬ ì ìš©**

## ğŸ—ï¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ í”„ë ˆì„ì›Œí¬ ê°œìš”

### ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì˜ í•µì‹¬ ê°œë…

#### ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì´ë€?
- **ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜**: ì—¬ëŸ¬ AI ì—ì´ì „íŠ¸ì˜ ìƒëª…ì£¼ê¸° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
- **ì‘ì—… ë¶„ë°°**: ë³µì¡í•œ ì‘ì—…ì„ ì ì ˆí•œ ì—ì´ì „íŠ¸ì— í• ë‹¹
- **í†µì‹  ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜**: ì—ì´ì „íŠ¸ ê°„ ë©”ì‹œì§€ ì „ë‹¬ ë° ë™ê¸°í™”
- **ìƒíƒœ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜**: ì „ì²´ ì‹œìŠ¤í…œì˜ ìƒíƒœ ì¶”ì  ë° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜

#### í”„ë ˆì„ì›Œí¬ ì„ íƒ ê¸°ì¤€
- **ë³µì¡ë„**: í”„ë¡œì íŠ¸ì˜ ë³µì¡ì„± ìˆ˜ì¤€
- **í™•ì¥ì„±**: ì—ì´ì „íŠ¸ ìˆ˜ì™€ ì‘ì—…ëŸ‰ ì¦ê°€ ëŒ€ì‘
- **ìœ ì—°ì„±**: ë‹¤ì–‘í•œ ì›Œí¬í”Œë¡œìš° ì§€ì›
- **í•™ìŠµ ê³¡ì„ **: íŒ€ì˜ ê¸°ìˆ  ìˆ˜ì¤€ê³¼ í•™ìŠµ ëŠ¥ë ¥

## ğŸ” í”„ë ˆì„ì›Œí¬ ìƒì„¸ ë¹„êµ

### 1. CrewAI: ì—­í•  ê¸°ë°˜ í˜‘ì—…

#### í•µì‹¬ íŠ¹ì§•
- **ì—­í•  ì¤‘ì‹¬**: ê° ì—ì´ì „íŠ¸ì—ê²Œ ëª…í™•í•œ ì—­í• ê³¼ ì±…ì„ ë¶€ì—¬
- **ìˆœì°¨ì  ì›Œí¬í”Œë¡œìš°**: ì‘ì—…ì´ ìˆœì„œëŒ€ë¡œ ì§„í–‰ë˜ëŠ” íŒŒì´í”„ë¼ì¸
- **ê³„ì¸µì  êµ¬ì¡°**: ê´€ë¦¬ì-ì‘ì—…ì ëª¨ë¸ ì§€ì›
- **ì§ê´€ì  API**: ê°„ë‹¨í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì¸í„°í˜ì´ìŠ¤

#### ì¥ì 
```python
# CrewAIì˜ ì§ê´€ì ì¸ ì—ì´ì „íŠ¸ ì •ì˜
from crewai import Agent, Task, Crew

# ì—ì´ì „íŠ¸ ì •ì˜
researcher = Agent(
    role='Research Analyst',
    goal='Gather market data and insights',
    backstory='Expert in market research with 10 years experience',
    verbose=True
)

writer = Agent(
    role='Content Writer',
    goal='Create engaging content based on research',
    backstory='Creative writer specializing in marketing content',
    verbose=True
)

# ì‘ì—… ì •ì˜
research_task = Task(
    description='Research the latest trends in AI technology',
    agent=researcher
)

writing_task = Task(
    description='Write a blog post about AI trends',
    agent=writer,
    dependencies=[research_task]
)

# í¬ë£¨ êµ¬ì„± ë° ì‹¤í–‰
crew = Crew(
    agents=[researcher, writer],
    tasks=[research_task, writing_task]
)

result = crew.kickoff()
```markdown

#### ë‹¨ì 
- **ì œí•œì  ë³‘ë ¬ì„±**: ìˆœì°¨ì  ì‹¤í–‰ì— ìµœì í™”
- **ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°**: ë™ì  ë¶„ê¸° ì²˜ë¦¬ ì–´ë ¤ì›€
- **ìƒíƒœ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜**: ë³µì¡í•œ ìƒíƒœ ì¶”ì  ì œí•œì 

#### ì í•©í•œ í”„ë¡œì íŠ¸
- **ë¬¸ì„œ ìƒì„±**: ì—°êµ¬ â†’ ì‘ì„± â†’ ê²€í†  íŒŒì´í”„ë¼ì¸
- **ë°ì´í„° ë¶„ì„**: ìˆ˜ì§‘ â†’ ì²˜ë¦¬ â†’ ì‹œê°í™” ì›Œí¬í”Œë¡œìš°
- **ì½˜í…ì¸  ì œì‘**: ê¸°íš â†’ ì œì‘ â†’ í¸ì§‘ í”„ë¡œì„¸ìŠ¤

### 2. AutoGen: ëŒ€í™”í˜• í˜‘ì—…

#### í•µì‹¬ íŠ¹ì§•
- **ëŒ€í™” ì¤‘ì‹¬**: ì—ì´ì „íŠ¸ ê°„ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”
- **ìœ ì—°í•œ ìƒí˜¸ì‘ìš©**: ë‹¤ì–‘í•œ í˜‘ì—… íŒ¨í„´ ì§€ì›
- **ë©€í‹° ì—ì´ì „íŠ¸ ëŒ€í™”**: ì—¬ëŸ¬ ì—ì´ì „íŠ¸ê°€ ë™ì‹œì— ì°¸ì—¬
- **ì‚¬ìš©ì ê°œì…**: ì¸ê°„ì´ ëŒ€í™”ì— ì°¸ì—¬ ê°€ëŠ¥

#### ì¥ì 
```python
# AutoGenì˜ ëŒ€í™”í˜• ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ
import autogen

# ì—ì´ì „íŠ¸ êµ¬ì„±
config_list = [
    {
        "model": "gpt-4",
        "api_key": "your-api-key"
    }
]

# ì½”ë“œ ì‘ì„± ì—ì´ì „íŠ¸
coder = autogen.AssistantAgent(
    name="Coder",
    system_message="You are a Python expert. Write clean, efficient code.",
    llm_config={"config_list": config_list}
)

# ì½”ë“œ ë¦¬ë·°ì–´ ì—ì´ì „íŠ¸
reviewer = autogen.AssistantAgent(
    name="Reviewer",
    system_message="You are a code reviewer. Check for bugs and improvements.",
    llm_config={"config_list": config_list}
)

# ì‚¬ìš©ì í”„ë¡ì‹œ
user_proxy = autogen.UserProxyAgent(
    name="User",
    human_input_mode="ALWAYS",
    max_consecutive_auto_reply=0
)

# ëŒ€í™” ì‹œì‘
user_proxy.initiate_chat(
    coder,
    message="Create a function to calculate fibonacci numbers"
)

# ë¦¬ë·°ì–´ê°€ ì°¸ì—¬
user_proxy.initiate_chat(
    reviewer,
    message="Review the fibonacci function for efficiency"
)
```markdown

#### ë‹¨ì 
- **êµ¬ì¡°í™” ë¶€ì¡±**: ëª…í™•í•œ ì›Œí¬í”Œë¡œìš° ì •ì˜ ì–´ë ¤ì›€
- **ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥ì„±**: ëŒ€í™”ì˜ ë°©í–¥ì„ ì œì–´í•˜ê¸° ì–´ë ¤ì›€
- **ë³µì¡í•œ ì„¤ì •**: ì´ˆê¸° ì„¤ì •ì´ ë³µì¡í•  ìˆ˜ ìˆìŒ

#### ì í•©í•œ í”„ë¡œì íŠ¸
- **ë¸Œë ˆì¸ìŠ¤í† ë°**: ì°½ì˜ì  ì•„ì´ë””ì–´ ë°œìƒ
- **ë¬¸ì œ í•´ê²°**: ë³µì¡í•œ ë¬¸ì œì— ëŒ€í•œ ë‹¤ê°ë„ ì ‘ê·¼
- **í˜‘ì—… ê°œë°œ**: ì¸ê°„ê³¼ AIê°€ í•¨ê»˜ ì‘ì—…

### 3. LangGraph: ìƒíƒœ ê¸°ë°˜ ì›Œí¬í”Œë¡œìš°

#### í•µì‹¬ íŠ¹ì§•
- **ìƒíƒœ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜**: ëª…í™•í•œ ìƒíƒœ ì „í™˜ê³¼ ì¶”ì 
- **ê²°ì •ë¡ ì **: ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì‹¤í–‰ íë¦„
- **ê·¸ë˜í”„ ê¸°ë°˜**: ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ê·¸ë˜í”„ë¡œ í‘œí˜„
- **ì¡°ê±´ë¶€ ë¶„ê¸°**: ìƒí™©ì— ë”°ë¥¸ ë™ì  ê²½ë¡œ ì„ íƒ

#### ì¥ì 
```python
# LangGraphì˜ ìƒíƒœ ê¸°ë°˜ ì›Œí¬í”Œë¡œìš°
from langgraph import StateGraph, END
from typing import TypedDict

# ìƒíƒœ ì •ì˜
class WorkflowState(TypedDict):
    input_data: str
    processed_data: str
    result: str
    error: str

# ë…¸ë“œ í•¨ìˆ˜ë“¤
def process_input(state: WorkflowState):
    return {"processed_data": f"Processed: {state['input_data']}"}

def validate_data(state: WorkflowState):
    if len(state['processed_data']) > 10:
        return {"result": "Valid data"}
    else:
        return {"error": "Data too short"}

def handle_error(state: WorkflowState):
    return {"result": f"Error handled: {state['error']}"}

# ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ êµ¬ì„±
workflow = StateGraph(WorkflowState)

# ë…¸ë“œ ì¶”ê°€
workflow.add_node("process", process_input)
workflow.add_node("validate", validate_data)
workflow.add_node("error_handler", handle_error)

# ì—£ì§€ ì¶”ê°€
workflow.add_edge("process", "validate")
workflow.add_conditional_edges(
    "validate",
    lambda state: "error" if "error" in state else "end",
    {
        "error": "error_handler",
        "end": END
    }
)
workflow.add_edge("error_handler", END)

# ì›Œí¬í”Œë¡œìš° ì»´íŒŒì¼ ë° ì‹¤í–‰
app = workflow.compile()
result = app.invoke({"input_data": "test data"})
```markdown

#### ë‹¨ì 
- **í•™ìŠµ ê³¡ì„ **: ê·¸ë˜í”„ ê°œë… ì´í•´ í•„ìš”
- **ë³µì¡ì„±**: ê°„ë‹¨í•œ ì‘ì—…ì— ê³¼ë„í•  ìˆ˜ ìˆìŒ
- **ìƒíƒœ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜**: ìƒíƒœ ì„¤ê³„ê°€ ë³µì¡í•  ìˆ˜ ìˆìŒ

#### ì í•©í•œ í”„ë¡œì íŠ¸
- **ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°**: ë‹¤ë‹¨ê³„ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
- **ì¡°ê±´ë¶€ ë¡œì§**: ìƒí™©ì— ë”°ë¥¸ ë¶„ê¸° ì²˜ë¦¬
- **ìƒíƒœ ì¶”ì **: ì§„í–‰ ìƒí™©ì„ ì •í™•íˆ ì¶”ì í•´ì•¼ í•˜ëŠ” ê²½ìš°

## ğŸ“Š ìƒì„¸ ë¹„êµ ë¶„ì„

### ê¸°ëŠ¥ë³„ ë¹„êµí‘œ

| ê¸°ëŠ¥ | CrewAI | AutoGen | LangGraph |
|------|--------|---------|-----------|
| **í•™ìŠµ ë‚œì´ë„** | â­â­ | â­â­â­ | â­â­â­â­ |
| **êµ¬ì¡°í™” ìˆ˜ì¤€** | â­â­â­â­ | â­â­ | â­â­â­â­â­ |
| **ìœ ì—°ì„±** | â­â­â­ | â­â­â­â­â­ | â­â­â­â­ |
| **í™•ì¥ì„±** | â­â­â­ | â­â­â­â­ | â­â­â­â­â­ |
| **ë””ë²„ê¹…** | â­â­â­â­ | â­â­ | â­â­â­â­â­ |
| **ë¬¸ì„œí™”** | â­â­â­â­ | â­â­â­ | â­â­â­ |

### ì„±ëŠ¥ ë¹„êµ

#### ì²˜ë¦¬ ì†ë„
```python
# ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ
import time

def benchmark_framework(framework_name, test_workflow):
    start_time = time.time()
    result = test_workflow.execute()
    end_time = time.time()
    
    return {
        "framework": framework_name,
        "execution_time": end_time - start_time,
        "success": result.success,
        "quality_score": result.quality_score
    }

# í…ŒìŠ¤íŠ¸ ê²°ê³¼ (ì˜ˆì‹œ)
results = [
    {"framework": "CrewAI", "execution_time": 2.3, "success": True, "quality_score": 85},
    {"framework": "AutoGen", "execution_time": 3.1, "success": True, "quality_score": 78},
    {"framework": "LangGraph", "execution_time": 1.8, "success": True, "quality_score": 92}
]
```markdown

#### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
- **CrewAI**: ì¤‘ê°„ (ìˆœì°¨ì  ì‹¤í–‰ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
- **AutoGen**: ë†’ìŒ (ëŒ€í™” ìƒíƒœ ìœ ì§€)
- **LangGraph**: ë‚®ìŒ (ìƒíƒœ ê¸°ë°˜ ìµœì í™”)

## ğŸ› ï¸ ì‹¤ìŠµ: í”„ë ˆì„ì›Œí¬ ì„ íƒ ë° êµ¬í˜„

### í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ ë¶„ì„

```python
class ProjectAnalyzer:
    def __init__(self):
        self.requirements = {}
        self.complexity_factors = []
    
    def analyze_project(self, project_description):
        # ë³µì¡ë„ ë¶„ì„
        complexity_score = self.calculate_complexity(project_description)
        
        # ì›Œí¬í”Œë¡œìš° íŒ¨í„´ ë¶„ì„
        workflow_pattern = self.identify_workflow_pattern(project_description)
        
        # ì—ì´ì „íŠ¸ ìˆ˜ ì¶”ì •
        estimated_agents = self.estimate_agent_count(project_description)
        
        # ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­ ë¶„ì„
        performance_requirements = self.analyze_performance_requirements(project_description)
        
        return {
            "complexity_score": complexity_score,
            "workflow_pattern": workflow_pattern,
            "estimated_agents": estimated_agents,
            "performance_requirements": performance_requirements
        }
    
    def recommend_framework(self, analysis_result):
        complexity = analysis_result["complexity_score"]
        workflow = analysis_result["workflow_pattern"]
        agents = analysis_result["estimated_agents"]
        
        if complexity < 3 and workflow == "sequential":
            return "CrewAI"
        elif workflow == "conversational" and agents <= 5:
            return "AutoGen"
        elif complexity >= 4 or workflow == "complex":
            return "LangGraph"
        else:
            return "CrewAI"  # ê¸°ë³¸ê°’
```markdown

### í”„ë ˆì„ì›Œí¬ë³„ êµ¬í˜„ ì˜ˆì‹œ

#### 1. CrewAI êµ¬í˜„
```python
# crewai_implementation.py
from crewai import Agent, Task, Crew

def create_crewai_workflow():
    # ì—ì´ì „íŠ¸ ì •ì˜
    analyst = Agent(
        role='Data Analyst',
        goal='Analyze data and provide insights',
        backstory='Expert in data analysis with statistical background',
        verbose=True
    )
    
    reporter = Agent(
        role='Report Writer',
        goal='Create comprehensive reports',
        backstory='Technical writer specializing in data reports',
        verbose=True
    )
    
    # ì‘ì—… ì •ì˜
    analysis_task = Task(
        description='Analyze the provided dataset and identify key trends',
        agent=analyst
    )
    
    report_task = Task(
        description='Create a detailed report based on the analysis',
        agent=reporter,
        dependencies=[analysis_task]
    )
    
    # í¬ë£¨ êµ¬ì„±
    crew = Crew(
        agents=[analyst, reporter],
        tasks=[analysis_task, report_task]
    )
    
    return crew
```markdown

#### 2. AutoGen êµ¬í˜„
```python
# autogen_implementation.py
import autogen

def create_autogen_workflow():
    config_list = [{"model": "gpt-4", "api_key": "your-api-key"}]
    
    # ì—ì´ì „íŠ¸ ì •ì˜
    analyst = autogen.AssistantAgent(
        name="Analyst",
        system_message="You are a data analyst. Analyze data and provide insights.",
        llm_config={"config_list": config_list}
    )
    
    writer = autogen.AssistantAgent(
        name="Writer",
        system_message="You are a technical writer. Create clear, comprehensive reports.",
        llm_config={"config_list": config_list}
    )
    
    # ì‚¬ìš©ì í”„ë¡ì‹œ
    user_proxy = autogen.UserProxyAgent(
        name="User",
        human_input_mode="NEVER",
        max_consecutive_auto_reply=2
    )
    
    # ê·¸ë£¹ ì±„íŒ… ì„¤ì •
    groupchat = autogen.GroupChat(
        agents=[analyst, writer, user_proxy],
        messages=[],
        max_round=10
    )
    
    manager = autogen.GroupChatManager(
        groupchat=groupchat,
        llm_config={"config_list": config_list}
    )
    
    return user_proxy, manager
```markdown

#### 3. LangGraph êµ¬í˜„
```python
# langgraph_implementation.py
from langgraph import StateGraph, END
from typing import TypedDict

class AnalysisState(TypedDict):
    data: str
    analysis: str
    report: str
    status: str

def create_langgraph_workflow():
    # ë…¸ë“œ í•¨ìˆ˜ë“¤
    def analyze_data(state: AnalysisState):
        return {"analysis": f"Analysis of {state['data']}", "status": "analyzed"}
    
    def generate_report(state: AnalysisState):
        return {"report": f"Report based on {state['analysis']}", "status": "completed"}
    
    def check_quality(state: AnalysisState):
        if len(state['analysis']) > 50:
            return {"status": "quality_ok"}
        else:
            return {"status": "quality_poor"}
    
    # ì›Œí¬í”Œë¡œìš° êµ¬ì„±
    workflow = StateGraph(AnalysisState)
    
    workflow.add_node("analyze", analyze_data)
    workflow.add_node("check", check_quality)
    workflow.add_node("report", generate_report)
    
    workflow.add_edge("analyze", "check")
    workflow.add_conditional_edges(
        "check",
        lambda state: state["status"],
        {
            "quality_ok": "report",
            "quality_poor": "analyze"
        }
    )
    workflow.add_edge("report", END)
    
    return workflow.compile()
```markdown

## ğŸš€ ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ

### í”„ë ˆì„ì›Œí¬ ê°„ ë§ˆì´ê·¸ë ˆì´ì…˜

#### 1. CrewAI â†’ LangGraph
```python
class CrewAIToLangGraphMigrator:
    def migrate_crew(self, crew):
        # CrewAIì˜ ì—ì´ì „íŠ¸ë¥¼ LangGraph ë…¸ë“œë¡œ ë³€í™˜
        nodes = {}
        edges = []
        
        for agent in crew.agents:
            nodes[agent.role] = self.create_node_from_agent(agent)
        
        for task in crew.tasks:
            if task.dependencies:
                for dep in task.dependencies:
                    edges.append((dep.agent.role, task.agent.role))
            else:
                edges.append(("start", task.agent.role))
        
        return self.build_langgraph_workflow(nodes, edges)
```markdown

#### 2. AutoGen â†’ CrewAI
```python
class AutoGenToCrewAIMigrator:
    def migrate_agents(self, autogen_agents):
        crewai_agents = []
        
        for agent in autogen_agents:
            crewai_agent = Agent(
                role=agent.name,
                goal=self.extract_goal_from_system_message(agent.system_message),
                backstory=self.generate_backstory(agent.name),
                verbose=True
            )
            crewai_agents.append(crewai_agent)
        
        return crewai_agents
```markdown

## ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### í”„ë ˆì„ì›Œí¬ë³„ ëª¨ë‹ˆí„°ë§

```python
class FrameworkMonitor:
    def __init__(self, framework_name):
        self.framework_name = framework_name
        self.metrics = {
            "execution_time": [],
            "success_rate": [],
            "error_count": [],
            "agent_utilization": []
        }
    
    def track_execution(self, start_time, end_time, success, errors):
        execution_time = end_time - start_time
        self.metrics["execution_time"].append(execution_time)
        self.metrics["success_rate"].append(1 if success else 0)
        self.metrics["error_count"].append(len(errors))
    
    def generate_report(self):
        return {
            "framework": self.framework_name,
            "average_execution_time": sum(self.metrics["execution_time"]) / len(self.metrics["execution_time"]),
            "success_rate": sum(self.metrics["success_rate"]) / len(self.metrics["success_rate"]),
            "total_errors": sum(self.metrics["error_count"])
        }
```

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„

ì´ ê°€ì´ë“œë¥¼ ì™„ë£Œí•œ í›„ì—ëŠ” ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•˜ì„¸ìš”:

1. **[1-9: CrewAIë¡œ ì²« ë²ˆì§¸ íŒ€ ë¹Œë”©](1-9-crewai-team-building.md)**
2. **[1-10: `constitution.md` ì‘ì„±](1-10-constitution-writing.md)**

## ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤

- [CrewAI Documentation](https://docs.crewai.com/)
- [AutoGen Documentation](https://microsoft.github.io/autogen/)
- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)

---

**"ì˜¬ë°”ë¥¸ ë„êµ¬ê°€ ì„±ê³µì˜ ì ˆë°˜"** - ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ í”„ë ˆì„ì›Œí¬ ì„ íƒì˜ í•µì‹¬
