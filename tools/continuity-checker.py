#!/usr/bin/env python3
"""
ì—°ì†ì„± ê²€ì‚¬ ë„êµ¬
ê°€ì´ë“œ ì‹œë¦¬ì¦ˆì˜ ì¼ê´€ì„±ê³¼ ì—°ì†ì„±ì„ ê²€ì‚¬í•©ë‹ˆë‹¤.
"""

import os
import re
import json
from pathlib import Path
from typing import Dict, List, Any, Set, Tuple, Optional
from dataclasses import dataclass
from datetime import datetime
import argparse
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class LinkIssue:
    """ë§í¬ ì´ìŠˆ ì •ë³´"""
    file_path: str
    line_number: int
    link_text: str
    link_url: str
    issue_type: str
    message: str


@dataclass
class ConsistencyIssue:
    """ì¼ê´€ì„± ì´ìŠˆ ì •ë³´"""
    file_path: str
    line_number: int
    issue_type: str
    message: str
    suggested_fix: str


@dataclass
class DependencyIssue:
    """ì˜ì¡´ì„± ì´ìŠˆ ì •ë³´"""
    file_path: str
    missing_dependency: str
    issue_type: str
    message: str


class LinkChecker:
    """ë§í¬ ê²€ì‚¬ í´ë˜ìŠ¤"""
    
    def __init__(self, base_path: str):
        self.base_path = Path(base_path)
        self.link_pattern = re.compile(r'\[([^\]]+)\]\(([^)]+)\)')
        self.anchor_pattern = re.compile(r'^#')
        self.external_pattern = re.compile(r'^https?://')
        self.file_pattern = re.compile(r'^[^#]+\.md$')
    
    def check_all_links(self, series_path: str) -> List[LinkIssue]:
        """ëª¨ë“  ë§í¬ ê²€ì‚¬"""
        issues = []
        series_path = Path(series_path)
        
        for md_file in series_path.rglob("*.md"):
            file_issues = self.check_file_links(md_file)
            issues.extend(file_issues)
        
        return issues
    
    def check_file_links(self, file_path: Path) -> List[LinkIssue]:
        """íŒŒì¼ ë‚´ ë§í¬ ê²€ì‚¬"""
        issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.split('\n')
            
            for line_num, line in enumerate(lines, 1):
                matches = self.link_pattern.findall(line)
                for link_text, link_url in matches:
                    issue = self.check_single_link(file_path, line_num, link_text, link_url)
                    if issue:
                        issues.append(issue)
        
        except Exception as e:
            logger.error(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {file_path}, {e}")
        
        return issues
    
    def check_single_link(self, file_path: Path, line_num: int, link_text: str, link_url: str) -> Optional[LinkIssue]:
        """ë‹¨ì¼ ë§í¬ ê²€ì‚¬"""
        # ì•µì»¤ ë§í¬ (í˜ì´ì§€ ë‚´ ë§í¬)
        if self.anchor_pattern.match(link_url):
            return self.check_anchor_link(file_path, line_num, link_text, link_url)
        
        # ì™¸ë¶€ ë§í¬
        elif self.external_pattern.match(link_url):
            return self.check_external_link(file_path, line_num, link_text, link_url)
        
        # ë‚´ë¶€ íŒŒì¼ ë§í¬
        elif self.file_pattern.match(link_url):
            return self.check_internal_link(file_path, line_num, link_text, link_url)
        
        return None
    
    def check_anchor_link(self, file_path: Path, line_num: int, link_text: str, link_url: str) -> Optional[LinkIssue]:
        """ì•µì»¤ ë§í¬ ê²€ì‚¬"""
        anchor = link_url[1:]  # # ì œê±°
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # í—¤ë”©ì—ì„œ ì•µì»¤ ì°¾ê¸°
            heading_pattern = re.compile(r'^#+\s+(.+)$', re.MULTILINE)
            headings = heading_pattern.findall(content)
            
            # ì•µì»¤ê°€ í—¤ë”©ì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            if not any(self.normalize_heading(heading) == anchor for heading in headings):
                return LinkIssue(
                    file_path=str(file_path),
                    line_number=line_num,
                    link_text=link_text,
                    link_url=link_url,
                    issue_type="broken_anchor",
                    message=f"ì•µì»¤ '{anchor}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                )
        
        except Exception as e:
            logger.error(f"ì•µì»¤ ê²€ì‚¬ ì‹¤íŒ¨: {file_path}, {e}")
        
        return None
    
    def check_external_link(self, file_path: Path, line_num: int, link_text: str, link_url: str) -> Optional[LinkIssue]:
        """ì™¸ë¶€ ë§í¬ ê²€ì‚¬ (ê¸°ë³¸ì ì¸ í˜•ì‹ ê²€ì‚¬ë§Œ)"""
        # URL í˜•ì‹ ê²€ì‚¬
        if not self.is_valid_url(link_url):
            return LinkIssue(
                file_path=str(file_path),
                line_number=line_num,
                link_text=link_text,
                link_url=link_url,
                issue_type="invalid_url",
                message=f"ì˜ëª»ëœ URL í˜•ì‹: {link_url}"
            )
        
        return None
    
    def check_internal_link(self, file_path: Path, line_num: int, link_text: str, link_url: str) -> Optional[LinkIssue]:
        """ë‚´ë¶€ íŒŒì¼ ë§í¬ ê²€ì‚¬"""
        # ìƒëŒ€ ê²½ë¡œ í•´ê²°
        target_path = file_path.parent / link_url
        
        if not target_path.exists():
            return LinkIssue(
                file_path=str(file_path),
                line_number=line_num,
                link_text=link_text,
                link_url=link_url,
                issue_type="broken_internal_link",
                message=f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {link_url}"
            )
        
        return None
    
    def normalize_heading(self, heading: str) -> str:
        """í—¤ë”©ì„ ì•µì»¤ í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”"""
        # ì†Œë¬¸ì ë³€í™˜, ê³µë°±ì„ í•˜ì´í”ˆìœ¼ë¡œ ë³€ê²½, íŠ¹ìˆ˜ë¬¸ì ì œê±°
        normalized = re.sub(r'[^\w\s-]', '', heading.lower())
        normalized = re.sub(r'[-\s]+', '-', normalized)
        return normalized.strip('-')
    
    def is_valid_url(self, url: str) -> bool:
        """URL ìœ íš¨ì„± ê²€ì‚¬"""
        url_pattern = re.compile(
            r'^https?://'  # http:// ë˜ëŠ” https://
            r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+[A-Z]{2,6}\.?|'  # ë„ë©”ì¸
            r'localhost|'  # localhost
            r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'  # IP
            r'(?::\d+)?'  # í¬íŠ¸
            r'(?:/?|[/?]\S+)$', re.IGNORECASE)
        return url_pattern.match(url) is not None


class ConsistencyChecker:
    """ì¼ê´€ì„± ê²€ì‚¬ í´ë˜ìŠ¤"""
    
    def __init__(self, base_path: str):
        self.base_path = Path(base_path)
        self.terminology = self.load_terminology()
        self.style_rules = self.load_style_rules()
    
    def load_terminology(self) -> Dict[str, List[str]]:
        """ìš©ì–´ ì‚¬ì „ ë¡œë“œ"""
        return {
            "AI ì—ì´ì „íŠ¸": ["AI agent", "autonomous agent", "intelligent agent"],
            "ëª…ì„¸ ê¸°ë°˜ ê°œë°œ": ["Spec-Driven Development", "SDD", "spec-driven development"],
            "ì—ì´ì „í‹±": ["agentic", "ì—ì´ì „í‹± AI", "agentic AI"],
            "ììœ¨ì„±": ["autonomy", "autonomous", "ììœ¨ì "],
            "ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜": ["orchestration", "ì¡°ìœ¨", "ê´€ë¦¬"]
        }
    
    def load_style_rules(self) -> Dict[str, Any]:
        """ìŠ¤íƒ€ì¼ ê·œì¹™ ë¡œë“œ"""
        return {
            "heading_levels": {
                "max_depth": 6,
                "required_sequence": True
            },
            "code_blocks": {
                "require_language": True,
                "max_length": 1000
            },
            "links": {
                "require_alt_text": True,
                "max_length": 100
            },
            "sections": {
                "required_sections": ["ê°œìš”", "í•™ìŠµ ëª©í‘œ", "ë‹¤ìŒ ë‹¨ê³„"],
                "recommended_sections": ["ì‹¤ìŠµ", "ê³ ê¸‰ ê¸°ëŠ¥", "ë¬¸ì œ í•´ê²°"]
            }
        }
    
    def check_series(self, series_path: str) -> List[ConsistencyIssue]:
        """ì‹œë¦¬ì¦ˆ ì¼ê´€ì„± ê²€ì‚¬"""
        issues = []
        series_path = Path(series_path)
        
        for md_file in series_path.rglob("*.md"):
            file_issues = self.check_file_consistency(md_file)
            issues.extend(file_issues)
        
        # ì‹œë¦¬ì¦ˆ ì „ì²´ ì¼ê´€ì„± ê²€ì‚¬
        series_issues = self.check_series_consistency(series_path)
        issues.extend(series_issues)
        
        return issues
    
    def check_file_consistency(self, file_path: Path) -> List[ConsistencyIssue]:
        """íŒŒì¼ ì¼ê´€ì„± ê²€ì‚¬"""
        issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.split('\n')
            
            # ìš©ì–´ ì¼ê´€ì„± ê²€ì‚¬
            terminology_issues = self.check_terminology_consistency(file_path, content)
            issues.extend(terminology_issues)
            
            # ìŠ¤íƒ€ì¼ ì¼ê´€ì„± ê²€ì‚¬
            style_issues = self.check_style_consistency(file_path, lines)
            issues.extend(style_issues)
            
            # êµ¬ì¡° ì¼ê´€ì„± ê²€ì‚¬
            structure_issues = self.check_structure_consistency(file_path, content)
            issues.extend(structure_issues)
        
        except Exception as e:
            logger.error(f"íŒŒì¼ ì¼ê´€ì„± ê²€ì‚¬ ì‹¤íŒ¨: {file_path}, {e}")
        
        return issues
    
    def check_terminology_consistency(self, file_path: Path, content: str) -> List[ConsistencyIssue]:
        """ìš©ì–´ ì¼ê´€ì„± ê²€ì‚¬"""
        issues = []
        
        for standard_term, variations in self.terminology.items():
            # í‘œì¤€ ìš©ì–´ê°€ ì‚¬ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if standard_term not in content:
                # ëŒ€ì•ˆ ìš©ì–´ê°€ ì‚¬ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸
                used_variations = [var for var in variations if var in content]
                if used_variations:
                    issues.append(ConsistencyIssue(
                        file_path=str(file_path),
                        line_number=0,
                        issue_type="terminology_inconsistency",
                        message=f"ìš©ì–´ ì¼ê´€ì„± ë¬¸ì œ: '{used_variations[0]}' ëŒ€ì‹  '{standard_term}' ì‚¬ìš© ê¶Œì¥",
                        suggested_fix=f"'{used_variations[0]}'ë¥¼ '{standard_term}'ë¡œ ë³€ê²½"
                    ))
        
        return issues
    
    def check_style_consistency(self, file_path: Path, lines: List[str]) -> List[ConsistencyIssue]:
        """ìŠ¤íƒ€ì¼ ì¼ê´€ì„± ê²€ì‚¬"""
        issues = []
        
        for line_num, line in enumerate(lines, 1):
            # í—¤ë”© ë ˆë²¨ ê²€ì‚¬
            heading_match = re.match(r'^(#{1,6})\s+(.+)$', line)
            if heading_match:
                level = len(heading_match.group(1))
                if level > self.style_rules["heading_levels"]["max_depth"]:
                    issues.append(ConsistencyIssue(
                        file_path=str(file_path),
                        line_number=line_num,
                        issue_type="heading_level_too_deep",
                        message=f"í—¤ë”© ë ˆë²¨ì´ ë„ˆë¬´ ê¹ŠìŠµë‹ˆë‹¤: {level}",
                        suggested_fix=f"í—¤ë”© ë ˆë²¨ì„ {self.style_rules['heading_levels']['max_depth']} ì´í•˜ë¡œ ì¡°ì •"
                    ))
            
            # ì½”ë“œ ë¸”ë¡ ê²€ì‚¬
            if line.strip().startswith('```'):
                if not re.match(r'^```\w+', line):
                    issues.append(ConsistencyIssue(
                        file_path=str(file_path),
                        line_number=line_num,
                        issue_type="code_block_missing_language",
                        message="ì½”ë“œ ë¸”ë¡ì— ì–¸ì–´ê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                        suggested_fix="ì½”ë“œ ë¸”ë¡ì— ì–¸ì–´ë¥¼ ì§€ì •í•˜ì„¸ìš” (ì˜ˆ: ```python)"
                    ))
        
        return issues
    
    def check_structure_consistency(self, file_path: Path, content: str) -> List[ConsistencyIssue]:
        """êµ¬ì¡° ì¼ê´€ì„± ê²€ì‚¬"""
        issues = []
        
        # í•„ìˆ˜ ì„¹ì…˜ ê²€ì‚¬
        required_sections = self.style_rules["sections"]["required_sections"]
        section_patterns = {
            "ê°œìš”": [r"## ğŸ“‹ ê°œìš”", r"## ğŸ“– ê°œìš”", r"## ê°œìš”"],
            "í•™ìŠµ ëª©í‘œ": [r"## ğŸ¯ í•™ìŠµ ëª©í‘œ", r"## í•™ìŠµ ëª©í‘œ"],
            "ë‹¤ìŒ ë‹¨ê³„": [r"## ğŸš€ ë‹¤ìŒ ë‹¨ê³„", r"## ë‹¤ìŒ ë‹¨ê³„"]
        }
        
        for section in required_sections:
            patterns = section_patterns.get(section, [f"## {section}"])
            found = False
            for pattern in patterns:
                if re.search(pattern, content):
                    found = True
                    break
            
            if not found:
                issues.append(ConsistencyIssue(
                    file_path=str(file_path),
                    line_number=0,
                    issue_type="missing_required_section",
                    message=f"í•„ìˆ˜ ì„¹ì…˜ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {section}",
                    suggested_fix=f"## {section} ì„¹ì…˜ì„ ì¶”ê°€í•˜ì„¸ìš”"
                ))
        
        return issues
    
    def check_series_consistency(self, series_path: Path) -> List[ConsistencyIssue]:
        """ì‹œë¦¬ì¦ˆ ì „ì²´ ì¼ê´€ì„± ê²€ì‚¬"""
        issues = []
        
        # ì‹œë¦¬ì¦ˆ ë²ˆí˜¸ ì¼ê´€ì„± ê²€ì‚¬
        series_files = list(series_path.rglob("*.md"))
        series_numbers = set()
        
        for file_path in series_files:
            # íŒŒì¼ëª…ì—ì„œ ì‹œë¦¬ì¦ˆ ë²ˆí˜¸ ì¶”ì¶œ
            match = re.search(r'(\d+)-(\d+)', file_path.name)
            if match:
                series_num = int(match.group(1))
                series_numbers.add(series_num)
        
        if len(series_numbers) > 1:
            issues.append(ConsistencyIssue(
                file_path=str(series_path),
                line_number=0,
                issue_type="series_number_inconsistency",
                message=f"ì‹œë¦¬ì¦ˆ ë²ˆí˜¸ê°€ ì¼ê´€ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {sorted(series_numbers)}",
                suggested_fix="ëª¨ë“  íŒŒì¼ì˜ ì‹œë¦¬ì¦ˆ ë²ˆí˜¸ë¥¼ í†µì¼í•˜ì„¸ìš”"
            ))
        
        return issues


class DependencyChecker:
    """ì˜ì¡´ì„± ê²€ì‚¬ í´ë˜ìŠ¤"""
    
    def __init__(self, base_path: str):
        self.base_path = Path(base_path)
        self.dependency_pattern = re.compile(r'\[([^\]]+)\]\(([^)]+\.md)\)')
    
    def check_dependencies(self, series_path: str) -> List[DependencyIssue]:
        """ì˜ì¡´ì„± ê²€ì‚¬"""
        issues = []
        series_path = Path(series_path)
        
        # ëª¨ë“  íŒŒì¼ì˜ ì˜ì¡´ì„± ë§µ ìƒì„±
        dependency_map = self.build_dependency_map(series_path)
        
        # ìˆœí™˜ ì˜ì¡´ì„± ê²€ì‚¬
        circular_issues = self.check_circular_dependencies(dependency_map)
        issues.extend(circular_issues)
        
        # ëˆ„ë½ëœ ì˜ì¡´ì„± ê²€ì‚¬
        missing_issues = self.check_missing_dependencies(series_path, dependency_map)
        issues.extend(missing_issues)
        
        return issues
    
    def build_dependency_map(self, series_path: Path) -> Dict[str, Set[str]]:
        """ì˜ì¡´ì„± ë§µ êµ¬ì¶•"""
        dependency_map = {}
        
        for md_file in series_path.rglob("*.md"):
            dependencies = set()
            
            try:
                with open(md_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ë‚´ë¶€ ë§í¬ì—ì„œ ì˜ì¡´ì„± ì¶”ì¶œ
                matches = self.dependency_pattern.findall(content)
                for link_text, link_url in matches:
                    if link_url.endswith('.md'):
                        # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                        target_path = md_file.parent / link_url
                        if target_path.exists():
                            dependencies.add(str(target_path.relative_to(series_path)))
                
                dependency_map[str(md_file.relative_to(series_path))] = dependencies
            
            except Exception as e:
                logger.error(f"ì˜ì¡´ì„± ë§µ êµ¬ì¶• ì‹¤íŒ¨: {md_file}, {e}")
        
        return dependency_map
    
    def check_circular_dependencies(self, dependency_map: Dict[str, Set[str]]) -> List[DependencyIssue]:
        """ìˆœí™˜ ì˜ì¡´ì„± ê²€ì‚¬"""
        issues = []
        
        def has_circular_dependency(file_path: str, visited: Set[str], rec_stack: Set[str]) -> bool:
            visited.add(file_path)
            rec_stack.add(file_path)
            
            for dependency in dependency_map.get(file_path, set()):
                if dependency not in visited:
                    if has_circular_dependency(dependency, visited, rec_stack):
                        return True
                elif dependency in rec_stack:
                    return True
            
            rec_stack.remove(file_path)
            return False
        
        for file_path in dependency_map:
            if has_circular_dependency(file_path, set(), set()):
                issues.append(DependencyIssue(
                    file_path=file_path,
                    missing_dependency="",
                    issue_type="circular_dependency",
                    message=f"ìˆœí™˜ ì˜ì¡´ì„±ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤: {file_path}"
                ))
        
        return issues
    
    def check_missing_dependencies(self, series_path: Path, dependency_map: Dict[str, Set[str]]) -> List[DependencyIssue]:
        """ëˆ„ë½ëœ ì˜ì¡´ì„± ê²€ì‚¬"""
        issues = []
        
        for file_path, dependencies in dependency_map.items():
            for dependency in dependencies:
                dependency_path = series_path / dependency
                if not dependency_path.exists():
                    issues.append(DependencyIssue(
                        file_path=file_path,
                        missing_dependency=dependency,
                        issue_type="missing_dependency",
                        message=f"ì˜ì¡´ì„± íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {dependency}"
                    ))
        
        return issues


class ContinuityChecker:
    """ì—°ì†ì„± ê²€ì‚¬ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, base_path: str):
        self.base_path = base_path
        self.link_checker = LinkChecker(base_path)
        self.consistency_checker = ConsistencyChecker(base_path)
        self.dependency_checker = DependencyChecker(base_path)
    
    def check_continuity(self, series_path: str) -> Dict[str, Any]:
        """ì—°ì†ì„± ê²€ì‚¬ ì‹¤í–‰"""
        logger.info(f"ì—°ì†ì„± ê²€ì‚¬ ì‹œì‘: {series_path}")
        
        # ë§í¬ ê²€ì‚¬
        link_issues = self.link_checker.check_all_links(series_path)
        logger.info(f"ë§í¬ ê²€ì‚¬ ì™„ë£Œ: {len(link_issues)}ê°œ ì´ìŠˆ ë°œê²¬")
        
        # ì¼ê´€ì„± ê²€ì‚¬
        consistency_issues = self.consistency_checker.check_series(series_path)
        logger.info(f"ì¼ê´€ì„± ê²€ì‚¬ ì™„ë£Œ: {len(consistency_issues)}ê°œ ì´ìŠˆ ë°œê²¬")
        
        # ì˜ì¡´ì„± ê²€ì‚¬
        dependency_issues = self.dependency_checker.check_dependencies(series_path)
        logger.info(f"ì˜ì¡´ì„± ê²€ì‚¬ ì™„ë£Œ: {len(dependency_issues)}ê°œ ì´ìŠˆ ë°œê²¬")
        
        # ê²°ê³¼ ì •ë¦¬
        result = {
            "timestamp": datetime.now().isoformat(),
            "series_path": series_path,
            "total_issues": len(link_issues) + len(consistency_issues) + len(dependency_issues),
            "link_issues": {
                "count": len(link_issues),
                "issues": [issue.__dict__ for issue in link_issues]
            },
            "consistency_issues": {
                "count": len(consistency_issues),
                "issues": [issue.__dict__ for issue in consistency_issues]
            },
            "dependency_issues": {
                "count": len(dependency_issues),
                "issues": [issue.__dict__ for issue in dependency_issues]
            }
        }
        
        return result
    
    def generate_report(self, result: Dict[str, Any], output_path: str):
        """ê²€ì‚¬ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ì—°ì†ì„± ê²€ì‚¬ ë³´ê³ ì„œ ìƒì„±: {output_path}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="ì—°ì†ì„± ê²€ì‚¬ ë„êµ¬")
    parser.add_argument("--series-path", required=True, help="ì‹œë¦¬ì¦ˆ ê²½ë¡œ")
    parser.add_argument("--base-path", default=".", help="ê¸°ì¤€ ê²½ë¡œ")
    parser.add_argument("--output", help="ë³´ê³ ì„œ ì¶œë ¥ ê²½ë¡œ")
    
    args = parser.parse_args()
    
    try:
        # ì—°ì†ì„± ê²€ì‚¬ê¸° ì´ˆê¸°í™”
        checker = ContinuityChecker(args.base_path)
        
        # ì—°ì†ì„± ê²€ì‚¬ ì‹¤í–‰
        result = checker.check_continuity(args.series_path)
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"ì—°ì†ì„± ê²€ì‚¬ ì™„ë£Œ:")
        print(f"  ì´ ì´ìŠˆ ìˆ˜: {result['total_issues']}")
        print(f"  ë§í¬ ì´ìŠˆ: {result['link_issues']['count']}")
        print(f"  ì¼ê´€ì„± ì´ìŠˆ: {result['consistency_issues']['count']}")
        print(f"  ì˜ì¡´ì„± ì´ìŠˆ: {result['dependency_issues']['count']}")
        
        # ë³´ê³ ì„œ ìƒì„±
        if args.output:
            checker.generate_report(result, args.output)
        
        # ì‹¬ê°í•œ ì´ìŠˆê°€ ìˆìœ¼ë©´ ì¢…ë£Œ ì½”ë“œ 1 ë°˜í™˜
        if result['total_issues'] > 0:
            return 1
    
    except Exception as e:
        logger.error(f"ì—°ì†ì„± ê²€ì‚¬ ì‹¤íŒ¨: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
