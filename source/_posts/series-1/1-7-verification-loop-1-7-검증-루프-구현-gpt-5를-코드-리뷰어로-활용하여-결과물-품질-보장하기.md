---
title: 1-7: ê²€ì¦ ë£¨í”„ êµ¬í˜„ - GPT-5ë¥¼ ì½”ë“œ ë¦¬ë·°ì–´ë¡œ í™œìš©í•˜ì—¬ ê²°ê³¼ë¬¼ í’ˆì§ˆ ë³´ì¥í•˜ê¸°
date: 2025-09-18 20:04:21
updated: 2025-09-18 20:04:21
categories: ["AI ê°€ì´ë“œ"]
tags: ["AI", "ê°€ì´ë“œ", "ìë™í™”"]
permalink: /series-1/1-7-verification-loop/
excerpt: 
toc: True
mathjax: True
comments: True
series:
  id: series-1
  title: ì‹œë¦¬ì¦ˆ 1: ì—ì´ì „í‹± ì¡°ì§ì˜ ê¸°ì´ˆ - ì•„í‚¤í…ì²˜ ì„¤ê³„ ë° êµ¬ì¶• ê°€ì´ë“œ
  position: 1
---
<h1 id="1-7-gpt-5">1-7: ê²€ì¦ ë£¨í”„ êµ¬í˜„ - GPT-5ë¥¼ ì½”ë“œ ë¦¬ë·°ì–´ë¡œ í™œìš©í•˜ì—¬ ê²°ê³¼ë¬¼ í’ˆì§ˆ ë³´ì¥í•˜ê¸°</h1>
<h2 id="_1">ğŸ“‹ ê°œìš”</h2>
<p>ê²€ì¦ ë£¨í”„ëŠ” AI ì—ì´ì „íŠ¸ê°€ ìƒì„±í•œ ê²°ê³¼ë¬¼ì˜ í’ˆì§ˆì„ ìë™ìœ¼ë¡œ ê²€ì¦í•˜ê³  ê°œì„ í•˜ëŠ” í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜ì…ë‹ˆë‹¤. GPT-5ë¥¼ ì½”ë“œ ë¦¬ë·°ì–´ë¡œ í™œìš©í•˜ì—¬ ì§€ì†ì ì¸ í’ˆì§ˆ í–¥ìƒì„ ë‹¬ì„±í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.</p>
<h2 id="_2">ğŸ¯ í•™ìŠµ ëª©í‘œ</h2>
<p>ì´ ê°€ì´ë“œë¥¼ ì™„ë£Œí•˜ë©´ ë‹¤ìŒì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:</p>
<ol>
<li><strong>ê²€ì¦ ë£¨í”„ì˜ ì›ë¦¬ì™€ ì¤‘ìš”ì„± ì´í•´</strong></li>
<li><strong>GPT-5 ê¸°ë°˜ ìë™ ì½”ë“œ ë¦¬ë·° ì‹œìŠ¤í…œ êµ¬ì¶•</strong></li>
<li><strong>í’ˆì§ˆ ì§€í‘œì™€ ê°œì„  ë©”ì»¤ë‹ˆì¦˜ ì„¤ê³„</strong></li>
<li><strong>ì‹¤ì œ í”„ë¡œì íŠ¸ì— ê²€ì¦ ë£¨í”„ ì ìš©</strong></li>
</ol>
<h2 id="_3">ğŸ”„ ê²€ì¦ ë£¨í”„ì˜ í•µì‹¬ ì›ë¦¬</h2>
<h3 id="_4">ê²€ì¦ ë£¨í”„ê°€ í•„ìš”í•œ ì´ìœ </h3>
<h4 id="ai">AI ìƒì„± ì½”ë“œì˜ ë¬¸ì œì </h4>
<ul>
<li><strong>ì¼ê´€ì„± ë¶€ì¡±</strong>: ê°™ì€ ìš”ì²­ë„ ë§¤ë²ˆ ë‹¤ë¥¸ ê²°ê³¼</li>
<li><strong>í’ˆì§ˆ í¸ì°¨</strong>: ë•Œë¡œëŠ” í›Œë¥­í•˜ì§€ë§Œ ë•Œë¡œëŠ” í˜•í¸ì—†ìŒ</li>
<li><strong>ê²€ì¦ ì–´ë ¤ì›€</strong>: ìì²´ ê²€ì¦ì´ ì–´ë ¤ì›€</li>
<li><strong>ê°œì„  ë¶€ì¡±</strong>: ì‹¤íŒ¨ì—ì„œ í•™ìŠµí•˜ì§€ ëª»í•¨</li>
</ul>
<h4 id="_5">ê²€ì¦ ë£¨í”„ì˜ ì¥ì </h4>
<ul>
<li><strong>í’ˆì§ˆ ë³´ì¥</strong>: ì¼ê´€ëœ ê³ í’ˆì§ˆ ê²°ê³¼ë¬¼</li>
<li><strong>ìë™ ê°œì„ </strong>: í”¼ë“œë°±ì„ í†µí•œ ì§€ì†ì  í–¥ìƒ</li>
<li><strong>ì‹ ë¢°ì„±</strong>: ê²€ì¦ëœ ê²°ê³¼ë¬¼ì— ëŒ€í•œ ì‹ ë¢°</li>
<li><strong>íš¨ìœ¨ì„±</strong>: ìˆ˜ë™ ê²€í†  ì‹œê°„ ë‹¨ì¶•</li>
</ul>
<h3 id="_6">ê²€ì¦ ë£¨í”„ ì•„í‚¤í…ì²˜</h3>
<pre class="codehilite"><code class="language-mermaid">graph TD
    A[ì½”ë“œ ìƒì„±] --&gt; B[GPT-5 ê²€ì¦ì]
    B --&gt; C{í’ˆì§ˆ ê²€ì¦}
    C --&gt;|í†µê³¼| D[ìµœì¢… ê²°ê³¼]
    C --&gt;|ì‹¤íŒ¨| E[í”¼ë“œë°± ìƒì„±]
    E --&gt; F[ê°œì„ ëœ ì½”ë“œ ìƒì„±]
    F --&gt; B
    G[í’ˆì§ˆ ì§€í‘œ] --&gt; B
    H[í•™ìŠµ ë°ì´í„°] --&gt; B
```markdown

## ğŸ› ï¸ GPT-5 ê¸°ë°˜ ê²€ì¦ ì‹œìŠ¤í…œ êµ¬í˜„

### ê¸°ë³¸ ê²€ì¦ ì‹œìŠ¤í…œ

```python
class GPT5CodeReviewer:
    def __init__(self, api_key):
        self.client = OpenAI(api_key=api_key)
        self.model = &quot;gpt-5&quot;
        self.quality_standards = self.load_quality_standards()

    def review_code(self, code, requirements, context):
        review_prompt = self.create_review_prompt(code, requirements, context)

        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: review_prompt}],
            temperature=0.3  # ì¼ê´€ëœ ê²€ì¦ì„ ìœ„í•´ ë‚®ì€ ì˜¨ë„
        )

        review_result = self.parse_review_result(response.choices[0].message.content)
        return review_result

    def create_review_prompt(self, code, requirements, context):
        return f&quot;&quot;&quot;
        ë‹¤ìŒ ì½”ë“œë¥¼ ì¢…í•©ì ìœ¼ë¡œ ê²€í† í•˜ê³  í’ˆì§ˆì„ í‰ê°€í•˜ì„¸ìš”:

        ## ì½”ë“œ
        ```typescript
        {code}
        ```python

        ## ìš”êµ¬ì‚¬í•­
        {requirements}

        ## ì»¨í…ìŠ¤íŠ¸
        {context}

        ## í’ˆì§ˆ ê¸°ì¤€
        {self.quality_standards}

        ë‹¤ìŒ í•­ëª©ë“¤ì„ í‰ê°€í•˜ì„¸ìš”:

        ### 1. ê¸°ëŠ¥ì  ì •í™•ì„± (0-100ì )
        - ìš”êµ¬ì‚¬í•­ ì¶©ì¡± ì—¬ë¶€
        - ë¡œì§ì˜ ì •í™•ì„±
        - ì—£ì§€ ì¼€ì´ìŠ¤ ì²˜ë¦¬

        ### 2. ì½”ë“œ í’ˆì§ˆ (0-100ì )
        - ê°€ë…ì„±
        - ìœ ì§€ë³´ìˆ˜ì„±
        - ì„±ëŠ¥
        - ë³´ì•ˆ

        ### 3. ì•„í‚¤í…ì²˜ ì¤€ìˆ˜ (0-100ì )
        - ì„¤ê³„ ì›ì¹™ ì¤€ìˆ˜
        - íŒ¨í„´ ì¼ê´€ì„±
        - ëª¨ë“ˆí™”

        ### 4. í…ŒìŠ¤íŠ¸ ê°€ëŠ¥ì„± (0-100ì )
        - í…ŒìŠ¤íŠ¸ ì‘ì„± ìš©ì´ì„±
        - ì˜ì¡´ì„± ì£¼ì…
        - ê²©ë¦¬ ê°€ëŠ¥ì„±

        ê° í•­ëª©ì— ëŒ€í•´ ì ìˆ˜ì™€ êµ¬ì²´ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•˜ê³ , 
        ì „ì²´ì ìœ¼ë¡œ í†µê³¼/ì‹¤íŒ¨ë¥¼ íŒì •í•˜ì„¸ìš”.
        &quot;&quot;&quot;

    def parse_review_result(self, review_text):
        # GPT-5ì˜ ê²€í†  ê²°ê³¼ë¥¼ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜
        lines = review_text.split('\n')

        scores = {}
        feedback = []
        overall_pass = False

        for line in lines:
            if &quot;ì ìˆ˜:&quot; in line or &quot;ì &quot; in line:
                # ì ìˆ˜ ì¶”ì¶œ
                score_match = re.search(r'(\d+)ì ', line)
                if score_match:
                    category = self.extract_category(line)
                    scores[category] = int(score_match.group(1))

            elif &quot;í”¼ë“œë°±:&quot; in line or &quot;ê°œì„ ì‚¬í•­:&quot; in line:
                # í”¼ë“œë°± ì¶”ì¶œ
                feedback.append(line.split(':', 1)[1].strip())

            elif &quot;í†µê³¼&quot; in line or &quot;ì‹¤íŒ¨&quot; in line:
                overall_pass = &quot;í†µê³¼&quot; in line

        return {
            &quot;passed&quot;: overall_pass,
            &quot;scores&quot;: scores,
            &quot;feedback&quot;: feedback,
            &quot;overall_score&quot;: sum(scores.values()) / len(scores) if scores else 0
        }
```markdown

### ê³ ê¸‰ ê²€ì¦ ê¸°ëŠ¥

#### 1. ë‹¤ì°¨ì› í’ˆì§ˆ í‰ê°€

```python
class MultiDimensionalReviewer(GPT5CodeReviewer):
    def __init__(self, api_key):
        super().__init__(api_key)
        self.dimension_weights = {
            &quot;functionality&quot;: 0.3,
            &quot;quality&quot;: 0.25,
            &quot;architecture&quot;: 0.2,
            &quot;testability&quot;: 0.15,
            &quot;security&quot;: 0.1
        }

    def comprehensive_review(self, code, requirements, context):
        # ê° ì°¨ì›ë³„ ìƒì„¸ ê²€í† 
        reviews = {}

        for dimension in self.dimension_weights.keys():
            reviews[dimension] = self.review_dimension(
                code, requirements, context, dimension
            )

        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì „ì²´ ì ìˆ˜ ê³„ì‚°
        overall_score = sum(
            reviews[dim][&quot;score&quot;] * weight 
            for dim, weight in self.dimension_weights.items()
        )

        # í†µê³¼/ì‹¤íŒ¨ íŒì •
        passed = overall_score &gt;= 70  # 70ì  ì´ìƒ í†µê³¼

        return {
            &quot;passed&quot;: passed,
            &quot;overall_score&quot;: overall_score,
            &quot;dimension_scores&quot;: reviews,
            &quot;recommendations&quot;: self.generate_recommendations(reviews)
        }

    def review_dimension(self, code, requirements, context, dimension):
        dimension_prompts = {
            &quot;functionality&quot;: self.get_functionality_prompt(),
            &quot;quality&quot;: self.get_quality_prompt(),
            &quot;architecture&quot;: self.get_architecture_prompt(),
            &quot;testability&quot;: self.get_testability_prompt(),
            &quot;security&quot;: self.get_security_prompt()
        }

        prompt = dimension_prompts[dimension].format(
            code=code, requirements=requirements, context=context
        )

        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}],
            temperature=0.3
        )

        return self.parse_dimension_result(response.choices[0].message.content)
```markdown

#### 2. ì ì‘í˜• ê²€ì¦ ê¸°ì¤€

```python
class AdaptiveReviewer(MultiDimensionalReviewer):
    def __init__(self, api_key):
        super().__init__(api_key)
        self.learning_history = []
        self.adaptive_criteria = {}

    def adaptive_review(self, code, requirements, context):
        # í”„ë¡œì íŠ¸ íŠ¹ì„±ì— ë§ëŠ” ê²€ì¦ ê¸°ì¤€ ì ìš©
        project_type = self.identify_project_type(requirements)

        if project_type in self.adaptive_criteria:
            criteria = self.adaptive_criteria[project_type]
        else:
            criteria = self.get_default_criteria()
            self.adaptive_criteria[project_type] = criteria

        # ì ì‘í˜• ê²€ì¦ ìˆ˜í–‰
        review_result = self.review_with_criteria(code, requirements, context, criteria)

        # í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘
        self.collect_learning_data(code, requirements, review_result)

        return review_result

    def identify_project_type(self, requirements):
        # ìš”êµ¬ì‚¬í•­ì„ ë¶„ì„í•˜ì—¬ í”„ë¡œì íŠ¸ ìœ í˜• ì‹ë³„
        type_indicators = {
            &quot;web_app&quot;: [&quot;ì›¹&quot;, &quot;ë¸Œë¼ìš°ì €&quot;, &quot;ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤&quot;],
            &quot;api&quot;: [&quot;API&quot;, &quot;ì—”ë“œí¬ì¸íŠ¸&quot;, &quot;REST&quot;],
            &quot;mobile&quot;: [&quot;ëª¨ë°”ì¼&quot;, &quot;ì•±&quot;, &quot;iOS&quot;, &quot;Android&quot;],
            &quot;data_science&quot;: [&quot;ë°ì´í„°&quot;, &quot;ë¶„ì„&quot;, &quot;ë¨¸ì‹ ëŸ¬ë‹&quot;, &quot;AI&quot;]
        }

        for project_type, indicators in type_indicators.items():
            if any(indicator in requirements for indicator in indicators):
                return project_type

        return &quot;general&quot;

    def collect_learning_data(self, code, requirements, review_result):
        learning_data = {
            &quot;code_complexity&quot;: self.assess_complexity(code),
            &quot;requirements_clarity&quot;: self.assess_requirements_clarity(requirements),
            &quot;review_result&quot;: review_result,
            &quot;timestamp&quot;: datetime.now()
        }

        self.learning_history.append(learning_data)

        # í•™ìŠµ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê²€ì¦ ê¸°ì¤€ ì—…ë°ì´íŠ¸
        self.update_adaptive_criteria()
```markdown

### í”¼ë“œë°± ìƒì„± ë° ê°œì„  ì‹œìŠ¤í…œ

#### 1. êµ¬ì²´ì  í”¼ë“œë°± ìƒì„±

```python
class FeedbackGenerator:
    def __init__(self, gpt5_api_key):
        self.client = OpenAI(api_key=gpt5_api_key)
        self.model = &quot;gpt-5&quot;

    def generate_improvement_feedback(self, code, review_result):
        feedback_prompt = f&quot;&quot;&quot;
        ë‹¤ìŒ ì½”ë“œ ê²€í†  ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ êµ¬ì²´ì ì¸ ê°œì„  ë°©ì•ˆì„ ì œì‹œí•˜ì„¸ìš”:

        ## ì›ë³¸ ì½”ë“œ
        ```typescript
        {code}
        ```python

        ## ê²€í†  ê²°ê³¼
        {review_result}

        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”:

        ### ğŸ”´ ì‹¬ê°í•œ ë¬¸ì œ (ì¦‰ì‹œ ìˆ˜ì • í•„ìš”)
        - [ë¬¸ì œì ]: [êµ¬ì²´ì  ì„¤ëª…]
        - [í•´ê²°ë°©ì•ˆ]: [ë‹¨ê³„ë³„ í•´ê²° ë°©ë²•]

        ### ğŸŸ¡ ê°œì„  ê¶Œì¥ (í’ˆì§ˆ í–¥ìƒ)
        - [ê°œì„ ì ]: [êµ¬ì²´ì  ì„¤ëª…]
        - [ê°œì„ ë°©ì•ˆ]: [êµ¬ì²´ì  êµ¬í˜„ ë°©ë²•]

        ### ğŸŸ¢ ì¶”ê°€ ê³ ë ¤ì‚¬í•­ (ì¥ê¸°ì  ê°œì„ )
        - [ê³ ë ¤ì‚¬í•­]: [êµ¬ì²´ì  ì„¤ëª…]
        - [êµ¬í˜„ë°©ì•ˆ]: [êµ¬ì²´ì  êµ¬í˜„ ë°©ë²•]

        ê° í”¼ë“œë°±ì— ëŒ€í•´ ì½”ë“œ ì˜ˆì‹œë¥¼ í¬í•¨í•˜ì„¸ìš”.
        &quot;&quot;&quot;

        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: feedback_prompt}],
            temperature=0.4
        )

        return response.choices[0].message.content
```markdown

#### 2. ìë™ ê°œì„  ì œì•ˆ

```python
class AutoImprovementSystem:
    def __init__(self, feedback_generator, code_generator):
        self.feedback_generator = feedback_generator
        self.code_generator = code_generator

    def suggest_improvements(self, code, review_result):
        # í”¼ë“œë°± ìƒì„±
        feedback = self.feedback_generator.generate_improvement_feedback(
            code, review_result
        )

        # ê°œì„ ëœ ì½”ë“œ ìƒì„±
        improved_code = self.code_generator.improve_code(code, feedback)

        # ê°œì„  ì‚¬í•­ ê²€ì¦
        improvement_verification = self.verify_improvements(
            code, improved_code, review_result
        )

        return {
            &quot;original_code&quot;: code,
            &quot;improved_code&quot;: improved_code,
            &quot;feedback&quot;: feedback,
            &quot;improvement_verification&quot;: improvement_verification
        }

    def verify_improvements(self, original_code, improved_code, original_review):
        verification_prompt = f&quot;&quot;&quot;
        ë‹¤ìŒ ì½”ë“œ ê°œì„ ì´ ì›ë³¸ ê²€í†  ê²°ê³¼ì˜ ë¬¸ì œì ì„ í•´ê²°í–ˆëŠ”ì§€ ê²€ì¦í•˜ì„¸ìš”:

        ## ì›ë³¸ ì½”ë“œ
        ```typescript
        {original_code}
        ```python

        ## ê°œì„ ëœ ì½”ë“œ
        ```typescript
        {improved_code}
        ```python

        ## ì›ë³¸ ê²€í†  ê²°ê³¼
        {original_review}

        ë‹¤ìŒì„ í‰ê°€í•˜ì„¸ìš”:
        1. ì›ë³¸ ë¬¸ì œì ì´ í•´ê²°ë˜ì—ˆëŠ”ê°€?
        2. ìƒˆë¡œìš´ ë¬¸ì œê°€ ë°œìƒí•˜ì§€ ì•Šì•˜ëŠ”ê°€?
        3. ì „ì²´ì ì¸ í’ˆì§ˆì´ í–¥ìƒë˜ì—ˆëŠ”ê°€?
        4. ì„±ëŠ¥ì— ë¶€ì •ì  ì˜í–¥ì„ ì£¼ì§€ ì•Šì•˜ëŠ”ê°€?

        ê° í•­ëª©ì— ëŒ€í•´ í†µê³¼/ì‹¤íŒ¨ë¥¼ íŒì •í•˜ê³  ì ìˆ˜ë¥¼ ì œê³µí•˜ì„¸ìš”.
        &quot;&quot;&quot;

        response = self.client.chat.completions.create(
            model=&quot;gpt-5&quot;,
            messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: verification_prompt}],
            temperature=0.3
        )

        return self.parse_verification_result(response.choices[0].message.content)
```markdown

## ğŸ“Š í’ˆì§ˆ ì§€í‘œ ë° ëª¨ë‹ˆí„°ë§

### í•µì‹¬ í’ˆì§ˆ ì§€í‘œ

#### 1. ì½”ë“œ í’ˆì§ˆ ì§€í‘œ
```python
class QualityMetrics:
    def __init__(self):
        self.metrics = {
            &quot;functionality_score&quot;: 0,
            &quot;quality_score&quot;: 0,
            &quot;architecture_score&quot;: 0,
            &quot;testability_score&quot;: 0,
            &quot;security_score&quot;: 0,
            &quot;overall_score&quot;: 0
        }

    def calculate_metrics(self, review_result):
        scores = review_result.get(&quot;scores&quot;, {})

        self.metrics[&quot;functionality_score&quot;] = scores.get(&quot;functionality&quot;, 0)
        self.metrics[&quot;quality_score&quot;] = scores.get(&quot;quality&quot;, 0)
        self.metrics[&quot;architecture_score&quot;] = scores.get(&quot;architecture&quot;, 0)
        self.metrics[&quot;testability_score&quot;] = scores.get(&quot;testability&quot;, 0)
        self.metrics[&quot;security_score&quot;] = scores.get(&quot;security&quot;, 0)

        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ì „ì²´ ì ìˆ˜ ê³„ì‚°
        weights = {
            &quot;functionality&quot;: 0.3,
            &quot;quality&quot;: 0.25,
            &quot;architecture&quot;: 0.2,
            &quot;testability&quot;: 0.15,
            &quot;security&quot;: 0.1
        }

        self.metrics[&quot;overall_score&quot;] = sum(
            scores.get(dim, 0) * weight 
            for dim, weight in weights.items()
        )

        return self.metrics
```markdown

#### 2. ê°œì„  ì¶”ì  ì§€í‘œ
```python
class ImprovementTracker:
    def __init__(self):
        self.improvement_history = []
        self.quality_trends = []

    def track_improvement(self, before_review, after_review):
        improvement_data = {
            &quot;before_score&quot;: before_review.get(&quot;overall_score&quot;, 0),
            &quot;after_score&quot;: after_review.get(&quot;overall_score&quot;, 0),
            &quot;improvement&quot;: after_review.get(&quot;overall_score&quot;, 0) - before_review.get(&quot;overall_score&quot;, 0),
            &quot;timestamp&quot;: datetime.now()
        }

        self.improvement_history.append(improvement_data)
        self.update_quality_trends()

        return improvement_data

    def get_improvement_statistics(self):
        if not self.improvement_history:
            return {&quot;average_improvement&quot;: 0, &quot;improvement_rate&quot;: 0}

        improvements = [data[&quot;improvement&quot;] for data in self.improvement_history]

        return {
            &quot;average_improvement&quot;: sum(improvements) / len(improvements),
            &quot;improvement_rate&quot;: len([i for i in improvements if i &gt; 0]) / len(improvements),
            &quot;max_improvement&quot;: max(improvements),
            &quot;min_improvement&quot;: min(improvements)
        }
```markdown

### ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

```python
class QualityDashboard:
    def __init__(self, reviewer, tracker):
        self.reviewer = reviewer
        self.tracker = tracker
        self.dashboard_data = {}

    def generate_dashboard(self):
        dashboard_data = {
            &quot;current_quality&quot;: self.get_current_quality_metrics(),
            &quot;quality_trends&quot;: self.get_quality_trends(),
            &quot;improvement_statistics&quot;: self.tracker.get_improvement_statistics(),
            &quot;top_issues&quot;: self.get_top_issues(),
            &quot;recommendations&quot;: self.get_recommendations()
        }

        return dashboard_data

    def get_current_quality_metrics(self):
        return {
            &quot;overall_score&quot;: self.reviewer.get_latest_score(),
            &quot;dimension_scores&quot;: self.reviewer.get_dimension_scores(),
            &quot;pass_rate&quot;: self.reviewer.get_pass_rate(),
            &quot;review_count&quot;: self.reviewer.get_review_count()
        }

    def get_quality_trends(self):
        return {
            &quot;score_trend&quot;: self.tracker.get_score_trend(),
            &quot;improvement_trend&quot;: self.tracker.get_improvement_trend(),
            &quot;issue_frequency&quot;: self.tracker.get_issue_frequency()
        }
```markdown

## ğŸ› ï¸ ì‹¤ìŠµ: ê²€ì¦ ë£¨í”„ ì‹œìŠ¤í…œ êµ¬ì¶•

### í”„ë¡œì íŠ¸ ì„¤ì •

```bash
# í”„ë¡œì íŠ¸ ì´ˆê¸°í™”
mkdir verification-loop-system
cd verification-loop-system

# ê°€ìƒí™˜ê²½ ì„¤ì •
python -m venv venv
source venv/bin/activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install openai python-dotenv matplotlib seaborn
```markdown

### ë©”ì¸ ì‹œìŠ¤í…œ êµ¬í˜„

```python
# main.py
import os
from dotenv import load_dotenv
from verification_system import VerificationSystem

def main():
    # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
    load_dotenv()

    # ê²€ì¦ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    verification_system = VerificationSystem(
        openai_api_key=os.getenv(&quot;OPENAI_API_KEY&quot;)
    )

    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    test_code = &quot;&quot;&quot;
    function calculateTotal(items) {
        let total = 0;
        for (let item of items) {
            total += item.price * item.quantity;
        }
        return total;
    }
    &quot;&quot;&quot;

    requirements = &quot;ì¥ë°”êµ¬ë‹ˆ ì´ ê¸ˆì•¡ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜&quot;

    # ê²€ì¦ ìˆ˜í–‰
    result = verification_system.review_and_improve(test_code, requirements)

    print(&quot;ê²€ì¦ ê²°ê³¼:&quot;)
    print(f&quot;í†µê³¼: {result['passed']}&quot;)
    print(f&quot;ì „ì²´ ì ìˆ˜: {result['overall_score']}&quot;)
    print(f&quot;í”¼ë“œë°±: {result['feedback']}&quot;)

    if not result['passed']:
        print(&quot;\nê°œì„ ëœ ì½”ë“œ:&quot;)
        print(result['improved_code'])

if __name__ == &quot;__main__&quot;:
    main()
</code></pre>

<h2 id="_7">ğŸš€ ë‹¤ìŒ ë‹¨ê³„</h2>
<p>ì´ ê°€ì´ë“œë¥¼ ì™„ë£Œí•œ í›„ì—ëŠ” ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•˜ì„¸ìš”:</p>
<ol>
<li><strong><a href="1-8-orchestration-framework.md">1-8: ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ í”„ë ˆì„ì›Œí¬ ì„ íƒ</a></strong></li>
<li><strong><a href="1-9-crewai-team-building.md">1-9: CrewAIë¡œ ì²« ë²ˆì§¸ íŒ€ ë¹Œë”©</a></strong></li>
</ol>
<h2 id="_8">ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤</h2>
<ul>
<li><a href="https://code-review.dev/">Code Review Best Practices</a></li>
<li><a href="https://qa-guidelines.dev/">Quality Assurance Guidelines</a></li>
<li><a href="https://automated-testing.dev/">Automated Testing Strategies</a></li>
</ul>
<hr />
<p><strong>"í’ˆì§ˆì€ ê²€ì¦ì—ì„œ ë‚˜ì˜¨ë‹¤"</strong> - ê²€ì¦ ë£¨í”„ì˜ í•µì‹¬ ì² í•™</p>