---
title: 1-1: ì—ì´ì „í‹± AI ì‹œì‘í•˜ê¸° - AI ì–´ì‹œìŠ¤í„´íŠ¸ì—ì„œ ììœ¨ì  í–‰ìœ„ìë¡œì˜ ì „í™˜
date: 2025-09-18 20:04:21
updated: 2025-09-18 20:04:21
categories: ["AI ê°€ì´ë“œ"]
tags: ["AI", "ê°€ì´ë“œ", "ìë™í™”"]
permalink: /series-1/1-1-agentic-ai-start/
excerpt: 
toc: True
mathjax: True
comments: True
series:
  id: series-1
  title: ì‹œë¦¬ì¦ˆ 1: ì—ì´ì „í‹± ì¡°ì§ì˜ ê¸°ì´ˆ - ì•„í‚¤í…ì²˜ ì„¤ê³„ ë° êµ¬ì¶• ê°€ì´ë“œ
  position: 1
---
<h1 id="1-1-ai-ai">1-1: ì—ì´ì „í‹± AI ì‹œì‘í•˜ê¸° - AI ì–´ì‹œìŠ¤í„´íŠ¸ì—ì„œ ììœ¨ì  í–‰ìœ„ìë¡œì˜ ì „í™˜</h1>
<h2 id="_1">ğŸ“‹ ê°œìš”</h2>
<p>ì´ ê°€ì´ë“œëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì˜ í•œê³„ë¥¼ ë„˜ì–´ì„œ ì§„ì •í•œ ììœ¨ì  í–‰ìœ„ì(Autonomous Agent)ë¡œ ì „í™˜í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤. ë‹¨ìˆœí•œ ë„êµ¬ì—ì„œ ì „ëµì  íŒŒíŠ¸ë„ˆë¡œ AIë¥¼ ë°œì „ì‹œí‚¤ëŠ” í•µì‹¬ ì›ë¦¬ì™€ êµ¬í˜„ ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.</p>
<h2 id="_2">ğŸ¯ í•™ìŠµ ëª©í‘œ</h2>
<p>ì´ ê°€ì´ë“œë¥¼ ì™„ë£Œí•˜ë©´ ë‹¤ìŒì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:</p>
<ol>
<li><strong>AI ì–´ì‹œìŠ¤í„´íŠ¸ì™€ AI ì—ì´ì „íŠ¸ì˜ ì°¨ì´ì  ì´í•´</strong></li>
<li><strong>ììœ¨ì„±ì˜ ì •ì˜ì™€ êµ¬í˜„ ë°©ë²• íŒŒì•…</strong></li>
<li><strong>ì—ì´ì „íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜ì˜ í•µì‹¬ ê°œë… ìŠµë“</strong></li>
<li><strong>ì²« ë²ˆì§¸ ììœ¨ ì—ì´ì „íŠ¸ êµ¬ì¶• ì‹¤ìŠµ</strong></li>
</ol>
<h2 id="ai-vs-ai">ğŸ¤– AI ì–´ì‹œìŠ¤í„´íŠ¸ vs AI ì—ì´ì „íŠ¸</h2>
<h3 id="ai">AI ì–´ì‹œìŠ¤í„´íŠ¸ì˜ í•œê³„</h3>
<p>í˜„ì¬ ëŒ€ë¶€ë¶„ì˜ AI ë„êµ¬ë“¤ì€ <strong>ë°˜ì‘í˜• ì–´ì‹œìŠ¤í„´íŠ¸</strong>ì…ë‹ˆë‹¤:</p>
<ul>
<li><strong>ìˆ˜ë™ì  ì‹¤í–‰</strong>: ì‚¬ìš©ìê°€ ëª…ë ¹ì„ ë‚´ë ¤ì•¼ë§Œ ì‘ë™</li>
<li><strong>ë‹¨ì¼ ì‘ì—…</strong>: í•œ ë²ˆì— í•˜ë‚˜ì˜ ì‘ì—…ë§Œ ì²˜ë¦¬</li>
<li><strong>ì»¨í…ìŠ¤íŠ¸ ë¶€ì¡±</strong>: ì´ì „ ì‘ì—…ì˜ ë§¥ë½ì„ ê¸°ì–µí•˜ì§€ ëª»í•¨</li>
<li><strong>ì˜ì¡´ì„± ë†’ìŒ</strong>: ì§€ì†ì ì¸ ì¸ê°„ì˜ ê°œì… í•„ìš”</li>
</ul>
<pre class="codehilite"><code class="language-python"># ì „í†µì ì¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ ì‚¬ìš©ë²•
response = openai.ChatCompletion.create(
    model=&quot;gpt-4&quot;,
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;ì´ ì½”ë“œë¥¼ ë¦¬íŒ©í† ë§í•´ì¤˜&quot;}]
)
# ì‚¬ìš©ìê°€ ë§¤ë²ˆ ìƒˆë¡œìš´ ìš”ì²­ì„ í•´ì•¼ í•¨
```markdown

### AI ì—ì´ì „íŠ¸ì˜ í˜ì‹ 

AI ì—ì´ì „íŠ¸ëŠ” **ëŠ¥ë™ì  í–‰ìœ„ì**ì…ë‹ˆë‹¤:

- **ììœ¨ì  ì‹¤í–‰**: ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´ ë…ë¦½ì ìœ¼ë¡œ í–‰ë™
- **ë‹¤ì¤‘ ì‘ì—…**: ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬
- **ìƒíƒœ ê¸°ì–µ**: ì´ì „ ì‘ì—…ê³¼ ê²°ê³¼ë¥¼ ê¸°ì–µí•˜ê³  í™œìš©
- **ìê¸° ìˆ˜ì •**: ì˜¤ë¥˜ ë°œìƒ ì‹œ ìŠ¤ìŠ¤ë¡œ ë¬¸ì œë¥¼ í•´ê²°

```python
# AI ì—ì´ì „íŠ¸ì˜ ììœ¨ì  ì‹¤í–‰
class AutonomousAgent:
    def __init__(self, goal):
        self.goal = goal
        self.memory = []
        self.tools = []

    def execute(self):
        while not self.is_goal_achieved():
            action = self.plan_next_action()
            result = self.execute_action(action)
            self.update_memory(action, result)
            self.learn_from_result(result)
```markdown

## ğŸ§  ììœ¨ì„±ì˜ í•µì‹¬ êµ¬ì„± ìš”ì†Œ

### 1. ëª©í‘œ ì§€í–¥ì  í–‰ë™ (Goal-Oriented Behavior)

ì—ì´ì „íŠ¸ëŠ” ëª…í™•í•œ ëª©í‘œë¥¼ ê°€ì§€ê³  í–‰ë™í•©ë‹ˆë‹¤:

```python
class GoalOrientedAgent:
    def __init__(self, primary_goal, constraints):
        self.primary_goal = primary_goal
        self.constraints = constraints
        self.current_state = &quot;initialized&quot;

    def plan_actions(self):
        &quot;&quot;&quot;ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ í–‰ë™ ê³„íš ìˆ˜ë¦½&quot;&quot;&quot;
        if self.current_state == &quot;initialized&quot;:
            return [&quot;analyze_requirements&quot;, &quot;create_plan&quot;, &quot;execute_plan&quot;]
        elif self.current_state == &quot;planning&quot;:
            return [&quot;gather_resources&quot;, &quot;implement_solution&quot;]
        # ... ë” ë§ì€ ìƒíƒœì™€ í–‰ë™
```markdown

### 2. í™˜ê²½ ì¸ì‹ ë° ìƒí˜¸ì‘ìš© (Environment Perception &amp; Interaction)

ì—ì´ì „íŠ¸ëŠ” ì£¼ë³€ í™˜ê²½ì„ ì¸ì‹í•˜ê³  ì ì ˆíˆ ë°˜ì‘í•©ë‹ˆë‹¤:

```python
class EnvironmentAwareAgent:
    def perceive_environment(self):
        &quot;&quot;&quot;í™˜ê²½ ìƒíƒœë¥¼ ì¸ì‹í•˜ê³  ë¶„ì„&quot;&quot;&quot;
        return {
            &quot;files&quot;: self.scan_file_system(),
            &quot;network&quot;: self.check_network_status(),
            &quot;resources&quot;: self.assess_available_resources(),
            &quot;errors&quot;: self.detect_errors()
        }

    def react_to_environment(self, perception):
        &quot;&quot;&quot;í™˜ê²½ ë³€í™”ì— ë”°ë¥¸ ì ì ˆí•œ ë°˜ì‘&quot;&quot;&quot;
        if perception[&quot;errors&quot;]:
            return self.handle_errors(perception[&quot;errors&quot;])
        elif perception[&quot;resources&quot;][&quot;cpu&quot;] &gt; 80:
            return self.optimize_performance()
        else:
            return self.continue_normal_operation()
```markdown

### 3. í•™ìŠµ ë° ì ì‘ (Learning &amp; Adaptation)

ì—ì´ì „íŠ¸ëŠ” ê²½í—˜ì„ í†µí•´ í•™ìŠµí•˜ê³  ê°œì„ ë©ë‹ˆë‹¤:

```python
class LearningAgent:
    def __init__(self):
        self.experience_memory = []
        self.success_patterns = []
        self.failure_patterns = []

    def learn_from_experience(self, action, result):
        &quot;&quot;&quot;í–‰ë™ê³¼ ê²°ê³¼ë¥¼ ê¸°ì–µí•˜ì—¬ í•™ìŠµ&quot;&quot;&quot;
        experience = {
            &quot;action&quot;: action,
            &quot;result&quot;: result,
            &quot;timestamp&quot;: time.time(),
            &quot;context&quot;: self.get_current_context()
        }
        self.experience_memory.append(experience)

        if result[&quot;success&quot;]:
            self.success_patterns.append(experience)
        else:
            self.failure_patterns.append(experience)

    def adapt_strategy(self):
        &quot;&quot;&quot;í•™ìŠµëœ íŒ¨í„´ì„ ë°”íƒ•ìœ¼ë¡œ ì „ëµ ì¡°ì •&quot;&quot;&quot;
        if len(self.failure_patterns) &gt; 3:
            return self.adopt_alternative_approach()
        return self.continue_current_strategy()
```markdown

## ğŸ—ï¸ ì—ì´ì „íŠ¸ ì•„í‚¤í…ì²˜ ì„¤ê³„

### ê¸°ë³¸ ì—ì´ì „íŠ¸ êµ¬ì¡°

```python
class AutonomousAgent:
    def __init__(self, name, role, capabilities):
        self.name = name
        self.role = role
        self.capabilities = capabilities
        self.memory = AgentMemory()
        self.planner = ActionPlanner()
        self.executor = ActionExecutor()
        self.validator = ResultValidator()

    def process_task(self, task):
        &quot;&quot;&quot;ì‘ì—…ì„ ì²˜ë¦¬í•˜ëŠ” ë©”ì¸ ë£¨í”„&quot;&quot;&quot;
        # 1. ì‘ì—… ë¶„ì„
        analysis = self.analyze_task(task)

        # 2. ê³„íš ìˆ˜ë¦½
        plan = self.planner.create_plan(analysis)

        # 3. ì‹¤í–‰
        results = []
        for action in plan:
            result = self.executor.execute(action)
            results.append(result)

            # 4. ê²€ì¦ ë° í”¼ë“œë°±
            validation = self.validator.validate(result, action)
            if not validation[&quot;valid&quot;]:
                self.handle_failure(action, result, validation)

        return self.synthesize_results(results)
```markdown

### ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ

```python
class AgentMemory:
    def __init__(self):
        self.short_term = {}  # í˜„ì¬ ì‘ì—… ê´€ë ¨ ì •ë³´
        self.long_term = {}   # í•™ìŠµëœ ì§€ì‹ê³¼ íŒ¨í„´
        self.episodic = []    # íŠ¹ì • ì—í”¼ì†Œë“œì˜ ê¸°ì–µ

    def store_experience(self, experience):
        &quot;&quot;&quot;ê²½í—˜ì„ ì ì ˆí•œ ë©”ëª¨ë¦¬ ì €ì¥ì†Œì— ì €ì¥&quot;&quot;&quot;
        if experience[&quot;type&quot;] == &quot;immediate&quot;:
            self.short_term[experience[&quot;key&quot;]] = experience[&quot;data&quot;]
        elif experience[&quot;type&quot;] == &quot;learning&quot;:
            self.long_term[experience[&quot;pattern&quot;]] = experience[&quot;knowledge&quot;]
        else:
            self.episodic.append(experience)

    def retrieve_relevant_memory(self, context):
        &quot;&quot;&quot;ì£¼ì–´ì§„ ë§¥ë½ê³¼ ê´€ë ¨ëœ ê¸°ì–µì„ ê²€ìƒ‰&quot;&quot;&quot;
        relevant = []
        for memory_type in [self.short_term, self.long_term]:
            for key, value in memory_type.items():
                if self.is_relevant(key, context):
                    relevant.append(value)
        return relevant
```markdown

## ğŸ› ï¸ ì‹¤ìŠµ: ì²« ë²ˆì§¸ ììœ¨ ì—ì´ì „íŠ¸ êµ¬ì¶•

### í”„ë¡œì íŠ¸ ì„¤ì •

```bash
# í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir autonomous-agent-demo
cd autonomous-agent-demo

# ê°€ìƒí™˜ê²½ ì„¤ì •
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install openai anthropic langchain crewai
```markdown

### ê¸°ë³¸ ì—ì´ì „íŠ¸ êµ¬í˜„

```python
# agent.py
import openai
import json
from typing import Dict, List, Any
from datetime import datetime

class SimpleAutonomousAgent:
    def __init__(self, name: str, role: str, api_key: str):
        self.name = name
        self.role = role
        self.api_key = api_key
        self.memory = []
        self.tools = []

        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        openai.api_key = api_key

    def add_tool(self, tool_name: str, tool_function):
        &quot;&quot;&quot;ì—ì´ì „íŠ¸ì— ë„êµ¬ ì¶”ê°€&quot;&quot;&quot;
        self.tools.append({
            &quot;name&quot;: tool_name,
            &quot;function&quot;: tool_function
        })

    def think(self, prompt: str) -&gt; str:
        &quot;&quot;&quot;ì—ì´ì „íŠ¸ì˜ ì‚¬ê³  ê³¼ì •&quot;&quot;&quot;
        system_prompt = f&quot;&quot;&quot;
        ë‹¹ì‹ ì€ {self.name}ì´ë¼ëŠ” ììœ¨ì  AI ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
        ì—­í• : {self.role}

        ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: {[tool['name'] for tool in self.tools]}

        ì£¼ì–´ì§„ ì‘ì—…ì— ëŒ€í•´ ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì„¸ìš”:
        1. ì‘ì—…ì„ ë¶„ì„í•˜ê³  ì´í•´í•˜ì„¸ìš”
        2. í•„ìš”í•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì„¸ìš”
        3. ë‹¨ê³„ë³„ ê³„íšì„ ìˆ˜ë¦½í•˜ì„¸ìš”
        4. ì‹¤í–‰ ê°€ëŠ¥í•œ í–‰ë™ì„ ì œì•ˆí•˜ì„¸ìš”
        &quot;&quot;&quot;

        response = openai.ChatCompletion.create(
            model=&quot;gpt-4&quot;,
            messages=[
                {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: system_prompt},
                {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}
            ],
            temperature=0.7
        )

        return response.choices[0].message.content

    def execute_plan(self, plan: str) -&gt; Dict[str, Any]:
        &quot;&quot;&quot;ê³„íšì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜&quot;&quot;&quot;
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ë³µì¡í•œ ì‹¤í–‰ ë¡œì§ì´ í•„ìš”
        result = {
            &quot;plan&quot;: plan,
            &quot;status&quot;: &quot;executed&quot;,
            &quot;timestamp&quot;: datetime.now().isoformat(),
            &quot;agent&quot;: self.name
        }

        # ë©”ëª¨ë¦¬ì— ì €ì¥
        self.memory.append(result)

        return result

    def learn_from_result(self, result: Dict[str, Any]):
        &quot;&quot;&quot;ê²°ê³¼ë¡œë¶€í„° í•™ìŠµ&quot;&quot;&quot;
        if result[&quot;status&quot;] == &quot;success&quot;:
            print(f&quot;âœ… {self.name}: ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.&quot;)
        else:
            print(f&quot;âŒ {self.name}: ì‘ì—… ì‹¤í–‰ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.&quot;)
            # ì‹¤íŒ¨ ì›ì¸ ë¶„ì„ ë° í•™ìŠµ ë¡œì§ ì¶”ê°€

# ì‚¬ìš© ì˜ˆì œ
def main():
    # ì—ì´ì „íŠ¸ ìƒì„±
    agent = SimpleAutonomousAgent(
        name=&quot;CodeMaster&quot;,
        role=&quot;ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ ì „ë¬¸ê°€&quot;,
        api_key=&quot;your-openai-api-key&quot;
    )

    # ë„êµ¬ ì¶”ê°€
    def code_analyzer(code):
        return f&quot;ì½”ë“œ ë¶„ì„ ê²°ê³¼: {len(code)} ì¤„ì˜ ì½”ë“œë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.&quot;

    agent.add_tool(&quot;code_analyzer&quot;, code_analyzer)

    # ì‘ì—… ì‹¤í–‰
    task = &quot;Python ì½”ë“œë¥¼ ë¦¬íŒ©í† ë§í•˜ê³  ìµœì í™”í•´ì£¼ì„¸ìš”&quot;

    # 1. ì‚¬ê³  ê³¼ì •
    thought = agent.think(task)
    print(&quot;ğŸ¤” ì—ì´ì „íŠ¸ì˜ ì‚¬ê³ :&quot;)
    print(thought)

    # 2. ê³„íš ì‹¤í–‰
    result = agent.execute_plan(thought)
    print(&quot;\nğŸ“‹ ì‹¤í–‰ ê²°ê³¼:&quot;)
    print(json.dumps(result, indent=2, ensure_ascii=False))

    # 3. í•™ìŠµ
    agent.learn_from_result(result)

if __name__ == &quot;__main__&quot;:
    main()
```markdown

### ê³ ê¸‰ ì—ì´ì „íŠ¸ ê¸°ëŠ¥

```python
# advanced_agent.py
class AdvancedAutonomousAgent(SimpleAutonomousAgent):
    def __init__(self, name: str, role: str, api_key: str):
        super().__init__(name, role, api_key)
        self.goals = []
        self.constraints = []
        self.preferences = {}

    def set_goal(self, goal: str, priority: int = 1):
        &quot;&quot;&quot;ëª©í‘œ ì„¤ì •&quot;&quot;&quot;
        self.goals.append({
            &quot;description&quot;: goal,
            &quot;priority&quot;: priority,
            &quot;status&quot;: &quot;active&quot;,
            &quot;created_at&quot;: datetime.now()
        })

    def add_constraint(self, constraint: str):
        &quot;&quot;&quot;ì œì•½ ì¡°ê±´ ì¶”ê°€&quot;&quot;&quot;
        self.constraints.append(constraint)

    def plan_with_goals(self, task: str) -&gt; str:
        &quot;&quot;&quot;ëª©í‘œì™€ ì œì•½ ì¡°ê±´ì„ ê³ ë ¤í•œ ê³„íš ìˆ˜ë¦½&quot;&quot;&quot;
        goals_context = f&quot;í˜„ì¬ ëª©í‘œ: {[g['description'] for g in self.goals]}&quot;
        constraints_context = f&quot;ì œì•½ ì¡°ê±´: {self.constraints}&quot;

        prompt = f&quot;&quot;&quot;
        {goals_context}
        {constraints_context}

        ì‘ì—…: {task}

        ìœ„ì˜ ëª©í‘œì™€ ì œì•½ ì¡°ê±´ì„ ê³ ë ¤í•˜ì—¬ ì‘ì—…ì„ ê³„íší•˜ì„¸ìš”.
        &quot;&quot;&quot;

        return self.think(prompt)

    def evaluate_progress(self) -&gt; Dict[str, Any]:
        &quot;&quot;&quot;ëª©í‘œ ë‹¬ì„± ì§„í–‰ ìƒí™© í‰ê°€&quot;&quot;&quot;
        progress = {
            &quot;total_goals&quot;: len(self.goals),
            &quot;completed_goals&quot;: len([g for g in self.goals if g[&quot;status&quot;] == &quot;completed&quot;]),
            &quot;active_goals&quot;: len([g for g in self.goals if g[&quot;status&quot;] == &quot;active&quot;]),
            &quot;completion_rate&quot;: 0
        }

        if progress[&quot;total_goals&quot;] &gt; 0:
            progress[&quot;completion_rate&quot;] = progress[&quot;completed_goals&quot;] / progress[&quot;total_goals&quot;]

        return progress
</code></pre>

<h2 id="_3">ğŸ”„ ì—ì´ì „íŠ¸ ìƒëª…ì£¼ê¸°</h2>
<h3 id="1">1. ì´ˆê¸°í™” ë‹¨ê³„</h3>
<ul>
<li>ì—ì´ì „íŠ¸ ìƒì„± ë° ê¸°ë³¸ ì„¤ì •</li>
<li>ì—­í• ê³¼ ì±…ì„ ì •ì˜</li>
<li>ë„êµ¬ ë° ëŠ¥ë ¥ ì„¤ì •</li>
</ul>
<h3 id="2">2. í•™ìŠµ ë‹¨ê³„</h3>
<ul>
<li>í™˜ê²½ê³¼ì˜ ìƒí˜¸ì‘ìš©ì„ í†µí•œ í•™ìŠµ</li>
<li>íŒ¨í„´ ì¸ì‹ ë° ì§€ì‹ ì¶•ì </li>
<li>ì „ëµ ë° í–‰ë™ ë°©ì‹ ê°œì„ </li>
</ul>
<h3 id="3">3. ì‹¤í–‰ ë‹¨ê³„</h3>
<ul>
<li>ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ ììœ¨ì  í–‰ë™</li>
<li>í™˜ê²½ ë³€í™”ì— ëŒ€í•œ ì ì‘</li>
<li>ì§€ì†ì ì¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§</li>
</ul>
<h3 id="4">4. ì§„í™” ë‹¨ê³„</h3>
<ul>
<li>ìƒˆë¡œìš´ ìƒí™©ì— ëŒ€í•œ ì ì‘</li>
<li>ëŠ¥ë ¥ í™•ì¥ ë° ì—…ê·¸ë ˆì´ë“œ</li>
<li>ë” ë³µì¡í•œ ì‘ì—… ìˆ˜í–‰</li>
</ul>
<h2 id="_4">ğŸ“Š ì„±ëŠ¥ ì¸¡ì • ì§€í‘œ</h2>
<h3 id="_5">ììœ¨ì„± ì§€í‘œ</h3>
<ul>
<li><strong>ììœ¨ ì™„ë£Œìœ¨</strong>: ì¸ê°„ ê°œì… ì—†ì´ ì™„ë£Œëœ ì‘ì—… ë¹„ìœ¨</li>
<li><strong>ì˜ì‚¬ê²°ì • ì†ë„</strong>: ìƒí™© ë¶„ì„ë¶€í„° í–‰ë™ê¹Œì§€ ì†Œìš” ì‹œê°„</li>
<li><strong>ì ì‘ì„±</strong>: ìƒˆë¡œìš´ ìƒí™©ì— ëŒ€í•œ ëŒ€ì‘ ëŠ¥ë ¥</li>
</ul>
<h3 id="_6">íš¨ìœ¨ì„± ì§€í‘œ</h3>
<ul>
<li><strong>ì‘ì—… ì™„ë£Œ ì‹œê°„</strong>: ë™ì¼ ì‘ì—…ì˜ í‰ê·  ì²˜ë¦¬ ì‹œê°„</li>
<li><strong>ì—ëŸ¬ ë³µêµ¬ ì‹œê°„</strong>: ë¬¸ì œ ë°œìƒ ì‹œ í•´ê²°ê¹Œì§€ ì†Œìš” ì‹œê°„</li>
<li><strong>í•™ìŠµ íš¨ê³¼ì„±</strong>: ê²½í—˜ì„ í†µí•œ ì„±ëŠ¥ ê°œì„  ì •ë„</li>
</ul>
<h2 id="_7">ğŸš€ ë‹¤ìŒ ë‹¨ê³„</h2>
<p>ì´ ê°€ì´ë“œë¥¼ ì™„ë£Œí•œ í›„ì—ëŠ” ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•˜ì„¸ìš”:</p>
<ol>
<li><strong><a href="1-2-spec-driven-development.md">1-2: ëª…ì„¸ ê¸°ë°˜ ê°œë°œ(ëª…ì„¸ ê¸°ë°˜ ê°œë°œ) ë§ˆìŠ¤í„°í•˜ê¸°</a></strong></li>
<li><strong><a href="1-3-principle-based-engineering.md">1-3: "ê°ì„± ì½”ë”©"ì„ ë„˜ì–´ì„œ</a></strong></li>
</ol>
<h2 id="_8">ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤</h2>
<ul>
<li><a href="https://platform.openai.com/docs">OpenAI API Documentation</a></li>
<li><a href="https://docs.anthropic.com/">Anthropic Claude API</a></li>
<li><a href="https://python.langchain.com/">LangChain Documentation</a></li>
<li><a href="https://docs.crewai.com/">CrewAI Framework</a></li>
</ul>
<hr />
<p><strong>"AI ì–´ì‹œìŠ¤í„´íŠ¸ì—ì„œ ììœ¨ì  íŒŒíŠ¸ë„ˆë¡œ"</strong> - ì—ì´ì „í‹± AIì˜ ì²« ê±¸ìŒ</p>