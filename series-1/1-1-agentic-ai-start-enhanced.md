# 1-1: ì—ì´ì „í‹± AI ì‹œì‘í•˜ê¸° - AI ì–´ì‹œìŠ¤í„´íŠ¸ì—ì„œ ììœ¨ì  í–‰ìœ„ìë¡œì˜ ì „í™˜

## ğŸ“‹ ê°œìš”

ì´ ê°€ì´ë“œëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì˜ í•œê³„ë¥¼ ë„˜ì–´ì„œ ì§„ì •í•œ ììœ¨ì  í–‰ìœ„ìë¡œ ì „í™˜í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤. ë‹¨ìˆœí•œ ë„êµ¬ì—ì„œ ì „ëµì  íŒŒíŠ¸ë„ˆë¡œ AIë¥¼ ë°œì „ì‹œí‚¤ëŠ” í•µì‹¬ ì›ë¦¬ì™€ êµ¬í˜„ ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.

## ğŸ¯ í•™ìŠµ ëª©í‘œ

ì´ ê°€ì´ë“œë¥¼ ì™„ë£Œí•˜ë©´ ë‹¤ìŒì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

1. **AI ì–´ì‹œìŠ¤í„´íŠ¸ì™€ AI ì—ì´ì „íŠ¸ì˜ ì°¨ì´ì  ì´í•´**: ë°˜ì‘í˜• ë„êµ¬ì™€ ììœ¨ì  í–‰ìœ„ìì˜ ê·¼ë³¸ì  ì°¨ì´ë¥¼ íŒŒì•…
2. **ììœ¨ì„±ì˜ ì •ì˜ì™€ êµ¬í˜„ ë°©ë²• íŒŒì•…**: ëª©í‘œ ì§€í–¥ì  í–‰ë™, í™˜ê²½ ì¸ì‹, í•™ìŠµ ëŠ¥ë ¥ì˜ í•µì‹¬ ìš”ì†Œ ì´í•´
3. **ì—ì´ì „íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜ì˜ í•µì‹¬ ê°œë… ìŠµë“**: ë©”ëª¨ë¦¬, ê³„íš, ì‹¤í–‰, ê²€ì¦ì˜ 4ë‹¨ê³„ ì•„í‚¤í…ì²˜ ì´í•´
4. **ì²« ë²ˆì§¸ ììœ¨ ì—ì´ì „íŠ¸ êµ¬ì¶• ì‹¤ìŠµ**: ì‹¤ì œ ë™ì‘í•˜ëŠ” ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ êµ¬í˜„

## ğŸ” ì‚¬ì „ ìš”êµ¬ì‚¬í•­

ì´ ê°€ì´ë“œë¥¼ ì‹œì‘í•˜ê¸° ì „ì— ë‹¤ìŒì„ ì™„ë£Œí•´ì•¼ í•©ë‹ˆë‹¤:

- Python ê¸°ë³¸ ë¬¸ë²• ì´í•´
- ê°ì²´ì§€í–¥ í”„ë¡œê·¸ë˜ë° ê°œë… ìˆ™ì§€
- API ì‚¬ìš© ê²½í—˜
- ê¸°ë³¸ì ì¸ ëª…ë ¹ì¤„ ì‚¬ìš©ë²•

## ğŸ“š í•µì‹¬ ê°œë…

### AI ì–´ì‹œìŠ¤í„´íŠ¸ vs AI ì—ì´ì „íŠ¸

í˜„ì¬ ëŒ€ë¶€ë¶„ì˜ AI ë„êµ¬ë“¤ì€ **ë°˜ì‘í˜• ì–´ì‹œìŠ¤í„´íŠ¸**ì…ë‹ˆë‹¤:

- **ìˆ˜ë™ì  ì‹¤í–‰**: ì‚¬ìš©ìê°€ ëª…ë ¹ì„ ë‚´ë ¤ì•¼ë§Œ ì‘ë™
- **ë‹¨ì¼ ì‘ì—…**: í•œ ë²ˆì— í•˜ë‚˜ì˜ ì‘ì—…ë§Œ ì²˜ë¦¬
- **ì»¨í…ìŠ¤íŠ¸ ë¶€ì¡±**: ì´ì „ ì‘ì—…ì˜ ë§¥ë½ì„ ê¸°ì–µí•˜ì§€ ëª»í•¨
- **ì˜ì¡´ì„± ë†’ìŒ**: ì§€ì†ì ì¸ ì¸ê°„ì˜ ê°œì… í•„ìš”

```python
# ì „í†µì ì¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ ì‚¬ìš©ë²•
response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "ì´ ì½”ë“œë¥¼ ë¦¬íŒ©í† ë§í•´ì¤˜"}]
)
# ì‚¬ìš©ìê°€ ë§¤ë²ˆ ìƒˆë¡œìš´ ìš”ì²­ì„ í•´ì•¼ í•¨
```

AI ì—ì´ì „íŠ¸ëŠ” **ëŠ¥ë™ì  í–‰ìœ„ì**ì…ë‹ˆë‹¤:

- **ììœ¨ì  ì‹¤í–‰**: ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•´ ë…ë¦½ì ìœ¼ë¡œ í–‰ë™
- **ë‹¤ì¤‘ ì‘ì—…**: ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬
- **ìƒíƒœ ê¸°ì–µ**: ì´ì „ ì‘ì—…ê³¼ ê²°ê³¼ë¥¼ ê¸°ì–µí•˜ê³  í™œìš©
- **ìê¸° ìˆ˜ì •**: ì˜¤ë¥˜ ë°œìƒ ì‹œ ìŠ¤ìŠ¤ë¡œ ë¬¸ì œë¥¼ í•´ê²°

```python
# AI ì—ì´ì „íŠ¸ì˜ ììœ¨ì  ì‹¤í–‰
class AutonomousAgent:
    def __init__(self, goal):
        self.goal = goal
        self.memory = []
        self.tools = []
    
    def execute(self):
        while not self.is_goal_achieved():
            action = self.plan_next_action()
            result = self.execute_action(action)
            self.update_memory(action, result)
            self.learn_from_result(result)
```

### ììœ¨ì„±ì˜ í•µì‹¬ êµ¬ì„± ìš”ì†Œ

#### 1. ëª©í‘œ ì§€í–¥ì  í–‰ë™ (Goal-Oriented Behavior)

ì—ì´ì „íŠ¸ëŠ” ëª…í™•í•œ ëª©í‘œë¥¼ ê°€ì§€ê³  í–‰ë™í•©ë‹ˆë‹¤:

```python
class GoalOrientedAgent:
    def __init__(self, primary_goal, constraints):
        self.primary_goal = primary_goal
        self.constraints = constraints
        self.current_state = "initialized"
    
    def plan_actions(self):
        """ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ í–‰ë™ ê³„íš ìˆ˜ë¦½"""
        if self.current_state == "initialized":
            return ["analyze_requirements", "create_plan", "execute_plan"]
        elif self.current_state == "planning":
            return ["gather_resources", "implement_solution"]
        # ... ë” ë§ì€ ìƒíƒœì™€ í–‰ë™
```

#### 2. í™˜ê²½ ì¸ì‹ ë° ìƒí˜¸ì‘ìš© (Environment Perception & Interaction)

ì—ì´ì „íŠ¸ëŠ” ì£¼ë³€ í™˜ê²½ì„ ì¸ì‹í•˜ê³  ì ì ˆíˆ ë°˜ì‘í•©ë‹ˆë‹¤:

```python
class EnvironmentAwareAgent:
    def perceive_environment(self):
        """í™˜ê²½ ìƒíƒœë¥¼ ì¸ì‹í•˜ê³  ë¶„ì„"""
        return {
            "files": self.scan_file_system(),
            "network": self.check_network_status(),
            "resources": self.assess_available_resources(),
            "errors": self.detect_errors()
        }
    
    def react_to_environment(self, perception):
        """í™˜ê²½ ë³€í™”ì— ë”°ë¥¸ ì ì ˆí•œ ë°˜ì‘"""
        if perception["errors"]:
            return self.handle_errors(perception["errors"])
        elif perception["resources"]["cpu"] > 80:
            return self.optimize_performance()
        else:
            return self.continue_normal_operation()
```

#### 3. í•™ìŠµ ë° ì ì‘ (Learning & Adaptation)

ì—ì´ì „íŠ¸ëŠ” ê²½í—˜ì„ í†µí•´ í•™ìŠµí•˜ê³  ê°œì„ ë©ë‹ˆë‹¤:

```python
class LearningAgent:
    def __init__(self):
        self.experience_memory = []
        self.success_patterns = []
        self.failure_patterns = []
    
    def learn_from_experience(self, action, result):
        """í–‰ë™ê³¼ ê²°ê³¼ë¥¼ ê¸°ì–µí•˜ì—¬ í•™ìŠµ"""
        experience = {
            "action": action,
            "result": result,
            "timestamp": time.time(),
            "context": self.get_current_context()
        }
        self.experience_memory.append(experience)
        
        if result["success"]:
            self.success_patterns.append(experience)
        else:
            self.failure_patterns.append(experience)
    
    def adapt_strategy(self):
        """í•™ìŠµëœ íŒ¨í„´ì„ ë°”íƒ•ìœ¼ë¡œ ì „ëµ ì¡°ì •"""
        if len(self.failure_patterns) > 3:
            return self.adopt_alternative_approach()
        return self.continue_current_strategy()
```

## ğŸ› ï¸ ì‹¤ìŠµ: ì²« ë²ˆì§¸ ììœ¨ ì—ì´ì „íŠ¸ êµ¬ì¶•

### 1ë‹¨ê³„: í”„ë¡œì íŠ¸ ì„¤ì •

```bash
# í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir autonomous-agent-demo
cd autonomous-agent-demo

# ê°€ìƒí™˜ê²½ ì„¤ì •
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install openai anthropic langchain crewai
```

### 2ë‹¨ê³„: ê¸°ë³¸ ì—ì´ì „íŠ¸ êµ¬í˜„

```python
# agent.py
import openai
import json
from typing import Dict, List, Any
from datetime import datetime

class SimpleAutonomousAgent:
    def __init__(self, name: str, role: str, api_key: str):
        self.name = name
        self.role = role
        self.api_key = api_key
        self.memory = []
        self.tools = []
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        openai.api_key = api_key
    
    def add_tool(self, tool_name: str, tool_function):
        """ì—ì´ì „íŠ¸ì— ë„êµ¬ ì¶”ê°€"""
        self.tools.append({
            "name": tool_name,
            "function": tool_function
        })
    
    def think(self, prompt: str) -> str:
        """ì—ì´ì „íŠ¸ì˜ ì‚¬ê³  ê³¼ì •"""
        system_prompt = f"""
        ë‹¹ì‹ ì€ {self.name}ì´ë¼ëŠ” ììœ¨ì  AI ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
        ì—­í• : {self.role}
        
        ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: {[tool['name'] for tool in self.tools]}
        
        ì£¼ì–´ì§„ ì‘ì—…ì— ëŒ€í•´ ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì„¸ìš”:
        1. ì‘ì—…ì„ ë¶„ì„í•˜ê³  ì´í•´í•˜ì„¸ìš”
        2. í•„ìš”í•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì„¸ìš”
        3. ë‹¨ê³„ë³„ ê³„íšì„ ìˆ˜ë¦½í•˜ì„¸ìš”
        4. ì‹¤í–‰ ê°€ëŠ¥í•œ í–‰ë™ì„ ì œì•ˆí•˜ì„¸ìš”
        """
        
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )
        
        return response.choices[0].message.content
    
    def execute_plan(self, plan: str) -> Dict[str, Any]:
        """ê³„íšì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ë³µì¡í•œ ì‹¤í–‰ ë¡œì§ì´ í•„ìš”
        result = {
            "plan": plan,
            "status": "executed",
            "timestamp": datetime.now().isoformat(),
            "agent": self.name
        }
        
        # ë©”ëª¨ë¦¬ì— ì €ì¥
        self.memory.append(result)
        
        return result
    
    def learn_from_result(self, result: Dict[str, Any]):
        """ê²°ê³¼ë¡œë¶€í„° í•™ìŠµ"""
        if result["status"] == "success":
            print(f"âœ… {self.name}: ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print(f"âŒ {self.name}: ì‘ì—… ì‹¤í–‰ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            # ì‹¤íŒ¨ ì›ì¸ ë¶„ì„ ë° í•™ìŠµ ë¡œì§ ì¶”ê°€
```

### 3ë‹¨ê³„: ê³ ê¸‰ ê¸°ëŠ¥ ì¶”ê°€

```python
# advanced_agent.py
class AdvancedAutonomousAgent(SimpleAutonomousAgent):
    def __init__(self, name: str, role: str, api_key: str):
        super().__init__(name, role, api_key)
        self.goals = []
        self.constraints = []
        self.preferences = {}
    
    def set_goal(self, goal: str, priority: int = 1):
        """ëª©í‘œ ì„¤ì •"""
        self.goals.append({
            "description": goal,
            "priority": priority,
            "status": "active",
            "created_at": datetime.now()
        })
    
    def add_constraint(self, constraint: str):
        """ì œì•½ ì¡°ê±´ ì¶”ê°€"""
        self.constraints.append(constraint)
    
    def plan_with_goals(self, task: str) -> str:
        """ëª©í‘œì™€ ì œì•½ ì¡°ê±´ì„ ê³ ë ¤í•œ ê³„íš ìˆ˜ë¦½"""
        goals_context = f"í˜„ì¬ ëª©í‘œ: {[g['description'] for g in self.goals]}"
        constraints_context = f"ì œì•½ ì¡°ê±´: {self.constraints}"
        
        prompt = f"""
        {goals_context}
        {constraints_context}
        
        ì‘ì—…: {task}
        
        ìœ„ì˜ ëª©í‘œì™€ ì œì•½ ì¡°ê±´ì„ ê³ ë ¤í•˜ì—¬ ì‘ì—…ì„ ê³„íší•˜ì„¸ìš”.
        """
        
        return self.think(prompt)
    
    def evaluate_progress(self) -> Dict[str, Any]:
        """ëª©í‘œ ë‹¬ì„± ì§„í–‰ ìƒí™© í‰ê°€"""
        progress = {
            "total_goals": len(self.goals),
            "completed_goals": len([g for g in self.goals if g["status"] == "completed"]),
            "active_goals": len([g for g in self.goals if g["status"] == "active"]),
            "completion_rate": 0
        }
        
        if progress["total_goals"] > 0:
            progress["completion_rate"] = progress["completed_goals"] / progress["total_goals"]
        
        return progress
```

## ğŸ”§ ê³ ê¸‰ ê¸°ëŠ¥

### ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„

```python
class AgentMemory:
    def __init__(self):
        self.short_term = {}  # í˜„ì¬ ì‘ì—… ê´€ë ¨ ì •ë³´
        self.long_term = {}   # í•™ìŠµëœ ì§€ì‹ê³¼ íŒ¨í„´
        self.episodic = []    # íŠ¹ì • ì—í”¼ì†Œë“œì˜ ê¸°ì–µ
    
    def store_experience(self, experience):
        """ê²½í—˜ì„ ì ì ˆí•œ ë©”ëª¨ë¦¬ ì €ì¥ì†Œì— ì €ì¥"""
        if experience["type"] == "immediate":
            self.short_term[experience["key"]] = experience["data"]
        elif experience["type"] == "learning":
            self.long_term[experience["pattern"]] = experience["knowledge"]
        else:
            self.episodic.append(experience)
    
    def retrieve_relevant_memory(self, context):
        """ì£¼ì–´ì§„ ë§¥ë½ê³¼ ê´€ë ¨ëœ ê¸°ì–µì„ ê²€ìƒ‰"""
        relevant = []
        for memory_type in [self.short_term, self.long_term]:
            for key, value in memory_type.items():
                if self.is_relevant(key, context):
                    relevant.append(value)
        return relevant
```

### ì—ì´ì „íŠ¸ ìƒëª…ì£¼ê¸° ê´€ë¦¬

```python
class AgentLifecycle:
    def __init__(self, agent):
        self.agent = agent
        self.current_phase = "initialization"
        self.phase_history = []
    
    def transition_to_phase(self, new_phase):
        """ë‹¨ê³„ ì „í™˜"""
        self.phase_history.append({
            "from": self.current_phase,
            "to": new_phase,
            "timestamp": datetime.now()
        })
        self.current_phase = new_phase
    
    def get_phase_actions(self):
        """í˜„ì¬ ë‹¨ê³„ì— ë”°ë¥¸ í–‰ë™ ë°˜í™˜"""
        phase_actions = {
            "initialization": ["setup", "configure", "validate"],
            "learning": ["observe", "experiment", "adapt"],
            "execution": ["plan", "act", "monitor"],
            "evolution": ["analyze", "improve", "expand"]
        }
        return phase_actions.get(self.current_phase, [])
```

## ğŸ“Š ëª¨ë²” ì‚¬ë¡€

### âœ… ê¶Œì¥ì‚¬í•­

- **ëª…í™•í•œ ëª©í‘œì™€ ì œì•½ ì¡°ê±´ì„ ì„¤ì •í•˜ì„¸ìš”**: ì—ì´ì „íŠ¸ê°€ ë¬´ì—‡ì„ í•´ì•¼ í•˜ê³  ë¬´ì—‡ì„ í•˜ì§€ ë§ì•„ì•¼ í•˜ëŠ”ì§€ ëª…í™•íˆ ì •ì˜
- **ì—ì´ì „íŠ¸ì˜ í–‰ë™ì„ ë¡œê¹…í•˜ì—¬ ë””ë²„ê¹…ì„ ìš©ì´í•˜ê²Œ í•˜ì„¸ìš”**: ëª¨ë“  ê²°ì •ê³¼ í–‰ë™ì„ ê¸°ë¡í•˜ì—¬ ë¬¸ì œ ë°œìƒ ì‹œ ì¶”ì  ê°€ëŠ¥
- **ì ì§„ì ìœ¼ë¡œ ë³µì¡ì„±ì„ ì¦ê°€ì‹œí‚¤ì„¸ìš”**: ê°„ë‹¨í•œ ê¸°ëŠ¥ë¶€í„° ì‹œì‘í•˜ì—¬ ì ì°¨ ê³ ê¸‰ ê¸°ëŠ¥ ì¶”ê°€
- **ì—ëŸ¬ ì²˜ë¦¬ì™€ ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜ì„ êµ¬í˜„í•˜ì„¸ìš”**: ì‹¤íŒ¨ ìƒí™©ì— ëŒ€í•œ ëŒ€ì‘ ë°©ì•ˆ ë§ˆë ¨

### âŒ ì£¼ì˜ì‚¬í•­

- **ë„ˆë¬´ ë³µì¡í•œ ì—ì´ì „íŠ¸ë¥¼ ì²˜ìŒë¶€í„° ë§Œë“¤ë ¤ê³  ì‹œë„í•˜ì§€ ë§ˆì„¸ìš”**: ë‹¨ê³„ì  ì ‘ê·¼ì´ ì¤‘ìš”
- **ì—ëŸ¬ ì²˜ë¦¬ ì—†ì´ êµ¬í˜„í•˜ì§€ ë§ˆì„¸ìš”**: ì˜ˆì™¸ ìƒí™©ì— ëŒ€í•œ ì²˜ë¦¬ê°€ í•„ìˆ˜
- **ë©”ëª¨ë¦¬ ê´€ë¦¬ì— ì†Œí™€í•˜ì§€ ë§ˆì„¸ìš”**: ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€ë¥¼ ìœ„í•œ ì •ë¦¬ ë¡œì§ í•„ìš”
- **í…ŒìŠ¤íŠ¸ ì—†ì´ ë°°í¬í•˜ì§€ ë§ˆì„¸ìš”**: ì¶©ë¶„í•œ í…ŒìŠ¤íŠ¸ë¥¼ ê±°ì³ ì•ˆì •ì„± í™•ë³´

## ğŸ” ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œ

**ë¬¸ì œ**: API í‚¤ ì˜¤ë¥˜
**í•´ê²°ì±…**: í™˜ê²½ ë³€ìˆ˜ì— ì˜¬ë°”ë¥¸ API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.

**ë¬¸ì œ**: ë©”ëª¨ë¦¬ ë¶€ì¡±
**í•´ê²°ì±…**: ì—ì´ì „íŠ¸ì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ëª¨ë‹ˆí„°ë§í•˜ê³  í•„ìš”ì‹œ ì •ë¦¬í•˜ì„¸ìš”.

**ë¬¸ì œ**: ì—ì´ì „íŠ¸ê°€ ë¬´í•œ ë£¨í”„ì— ë¹ ì§
**í•´ê²°ì±…**: ìµœëŒ€ ì‹¤í–‰ ì‹œê°„ì´ë‚˜ ë°˜ë³µ íšŸìˆ˜ ì œí•œì„ ì„¤ì •í•˜ì„¸ìš”.

### ë””ë²„ê¹… íŒ

- **ë¡œê¹… ë ˆë²¨ì„ ì¡°ì •í•˜ì—¬ ìƒì„¸í•œ ì •ë³´ ìˆ˜ì§‘**
- **ì—ì´ì „íŠ¸ì˜ ì˜ì‚¬ê²°ì • ê³¼ì •ì„ ì‹œê°í™”**
- **ë©”ëª¨ë¦¬ ìƒíƒœë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ ì ê²€**
- **ì„±ëŠ¥ ë©”íŠ¸ë¦­ì„ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ë³‘ëª© ì§€ì  íŒŒì•…**

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”

### ë©”ëª¨ë¦¬ ìµœì í™”

```python
class MemoryOptimizer:
    def __init__(self, max_memory_size=1000):
        self.max_memory_size = max_memory_size
    
    def optimize_memory(self, agent_memory):
        """ë©”ëª¨ë¦¬ ìµœì í™”"""
        if len(agent_memory.episodic) > self.max_memory_size:
            # ì˜¤ë˜ëœ ê¸°ì–µ ì œê±°
            agent_memory.episodic = agent_memory.episodic[-self.max_memory_size:]
        
        # ì¤‘ìš”ë„ê°€ ë‚®ì€ ë‹¨ê¸° ê¸°ì–µ ì •ë¦¬
        self.cleanup_short_term_memory(agent_memory)
```

### ì‹¤í–‰ ì†ë„ ìµœì í™”

```python
class PerformanceOptimizer:
    def __init__(self):
        self.cache = {}
        self.performance_metrics = {}
    
    def cache_frequent_operations(self, operation, result):
        """ìì£¼ ì‚¬ìš©ë˜ëŠ” ì—°ì‚° ê²°ê³¼ ìºì‹±"""
        self.cache[operation] = result
    
    def optimize_execution_plan(self, plan):
        """ì‹¤í–‰ ê³„íš ìµœì í™”"""
        # ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥í•œ ì‘ì—… ì‹ë³„
        parallel_tasks = self.identify_parallel_tasks(plan)
        # ì˜ì¡´ì„± ê·¸ë˜í”„ ìµœì í™”
        optimized_plan = self.optimize_dependency_graph(plan)
        return optimized_plan
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì „ëµ

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

```python
import unittest

class TestAutonomousAgent(unittest.TestCase):
    def setUp(self):
        self.agent = SimpleAutonomousAgent("TestAgent", "Tester", "test-key")
    
    def test_agent_initialization(self):
        self.assertEqual(self.agent.name, "TestAgent")
        self.assertEqual(self.agent.role, "Tester")
        self.assertEqual(len(self.agent.memory), 0)
    
    def test_goal_setting(self):
        self.agent.set_goal("Test Goal", priority=1)
        self.assertEqual(len(self.agent.goals), 1)
        self.assertEqual(self.agent.goals[0]["description"], "Test Goal")
    
    def test_memory_storage(self):
        experience = {"type": "test", "data": "test_data"}
        self.agent.memory.append(experience)
        self.assertEqual(len(self.agent.memory), 1)
```

### í†µí•© í…ŒìŠ¤íŠ¸

```python
class TestAgentIntegration(unittest.TestCase):
    def test_full_workflow(self):
        agent = AdvancedAutonomousAgent("IntegrationTest", "Tester", "test-key")
        agent.set_goal("Complete test workflow")
        
        # ì „ì²´ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸
        result = agent.execute_workflow("test task")
        self.assertTrue(result["success"])
        self.assertGreater(len(agent.memory), 0)
```

## ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸

ì´ ê°€ì´ë“œë¥¼ ì™„ë£Œí–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:

- [ ] AI ì–´ì‹œìŠ¤í„´íŠ¸ì™€ ì—ì´ì „íŠ¸ì˜ ì°¨ì´ì ì„ ì´í•´í–ˆìŠµë‹ˆë‹¤
- [ ] ììœ¨ì„±ì˜ 3ê°€ì§€ í•µì‹¬ êµ¬ì„± ìš”ì†Œë¥¼ íŒŒì•…í–ˆìŠµë‹ˆë‹¤
- [ ] ê¸°ë³¸ ì—ì´ì „íŠ¸ í´ë˜ìŠ¤ë¥¼ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤
- [ ] ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì„ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤
- [ ] ì—ì´ì „íŠ¸ ìƒëª…ì£¼ê¸°ë¥¼ ì´í•´í–ˆìŠµë‹ˆë‹¤
- [ ] í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ ì‘ì„±í–ˆìŠµë‹ˆë‹¤
- [ ] ì„±ëŠ¥ ìµœì í™” ê¸°ë²•ì„ ì ìš©í–ˆìŠµë‹ˆë‹¤

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„

ì´ ê°€ì´ë“œë¥¼ ì™„ë£Œí•œ í›„ì—ëŠ” ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•˜ì„¸ìš”:

1. **[1-2: ëª…ì„¸ ê¸°ë°˜ ê°œë°œ(SDD) ë§ˆìŠ¤í„°í•˜ê¸°](1-2-spec-driven-development.md)**: Spec Kitìœ¼ë¡œ ì²« í”„ë¡œì íŠ¸ ì‹œì‘í•˜ê¸°
2. **[1-3: ì›ì¹™ ê¸°ë°˜ ì—”ì§€ë‹ˆì–´ë§ìœ¼ë¡œì˜ ì „í™˜](1-3-principle-based-engineering.md)**: ê°ì„± ì½”ë”©ì„ ë„˜ì–´ì„œ ì›ì¹™ ê¸°ë°˜ ì—”ì§€ë‹ˆì–´ë§ìœ¼ë¡œ

## ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤

- [OpenAI API Documentation](https://platform.openai.com/docs): OpenAI API ê³µì‹ ë¬¸ì„œ
- [CrewAI Framework](https://docs.crewai.com/): CrewAI í”„ë ˆì„ì›Œí¬ ë¬¸ì„œ
- [LangChain Documentation](https://python.langchain.com/): LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¬¸ì„œ
- [Anthropic Claude API](https://docs.anthropic.com/): Claude API ë¬¸ì„œ

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

ì´ ê°€ì´ë“œë¥¼ ê°œì„ í•˜ëŠ” ë° ë„ì›€ì„ ì£¼ì„¸ìš”:

- [ì´ìŠˆ ë¦¬í¬íŠ¸](https://github.com/your-repo/issues)
- [í’€ ë¦¬í€˜ìŠ¤íŠ¸ ê°€ì´ë“œ](CONTRIBUTING.md)
- [ê¸°ì—¬ ê°€ì´ë“œë¼ì¸](CONTRIBUTING.md)

---

**"AI ì–´ì‹œìŠ¤í„´íŠ¸ì—ì„œ ììœ¨ì  íŒŒíŠ¸ë„ˆë¡œ"** - ì—ì´ì „í‹± AIì˜ ì²« ê±¸ìŒ
