# Hexo í†µí•© ì„¤ì • ê°€ì´ë“œ

## ê°œìš”

ì´ ê°€ì´ë“œëŠ” ê¸°ì¡´ ê°€ì´ë“œ ì‹œë¦¬ì¦ˆë¥¼ Hexo ê¸°ë°˜ GitHub Pages ë¸”ë¡œê·¸ë¡œ í†µí•©í•˜ëŠ” êµ¬ì²´ì ì¸ ì„¤ì • ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸš€ 1ë‹¨ê³„: Hexo ì‚¬ì´íŠ¸ ì´ˆê¸°í™”

### 1.1 í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±

```bash
# ê¸°ì¡´ spec ë””ë ‰í† ë¦¬ì—ì„œ ì‹œì‘
cd /root/spec

# Hexo ì‚¬ì´íŠ¸ ì´ˆê¸°í™”
npx hexo init publishing-system
cd publishing-system

# í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p source/_posts/series-1
mkdir -p source/_posts/series-2
mkdir -p source/_posts/series-3
mkdir -p source/_posts/series-4
mkdir -p source/_posts/series-5
mkdir -p source/_books
mkdir -p source/_pages
mkdir -p source/_data
mkdir -p specs/series
mkdir -p specs/books
mkdir -p specs/agents
mkdir -p agents
mkdir -p scripts
mkdir -p templates
```

### 1.2 Hexo ì„¤ì • íŒŒì¼

```yaml
# _config.yml
title: AI ê°€ì´ë“œ ì‹œë¦¬ì¦ˆ
subtitle: Spec Driven Developmentë¡œ ë°°ìš°ëŠ” AIì™€ ìë™í™”
description: AIì™€ ìë™í™”ë¥¼ í†µí•´ 100ë°° ìƒì‚°ì„±ì„ ë‹¬ì„±í•˜ëŠ” ì™„ì „í•œ ê°€ì´ë“œ
author: AI Agent Team
language: ko
timezone: Asia/Seoul

# URL ì„¤ì •
url: https://kronenz.github.io
root: /
permalink: :year/:month/:day/:title/
permalink_defaults:

# ë””ë ‰í† ë¦¬ ì„¤ì •
source_dir: source
public_dir: public
tag_dir: tags
archive_dir: archives
category_dir: categories
code_dir: downloads/code
i18n_dir: :lang
skip_render:

# ê¸€ì“°ê¸° ì„¤ì •
new_post_name: :title.md
default_layout: post
titlecase: false
external_link: true
filename_case: 0
render_drafts: false
post_asset_folder: false
relative_link: false
future: true

# ì½”ë“œ í•˜ì´ë¼ì´íŒ…
highlight:
  enable: true
  line_number: true
  auto_detect: false
  tab_replace:

# ì¹´í…Œê³ ë¦¬ ë° íƒœê·¸
default_category: uncategorized
category_map:
  'AI ê°€ì´ë“œ': ai-guide
  'ìë™í™”': automation
  'ìƒì‚°ì„±': productivity
  'DevOps': devops
  'Devin ì•„í‚¤í…ì²˜': devin-architecture
tag_map:

# ë‚ ì§œ í˜•ì‹
date_format: YYYY-MM-DD
time_format: HH:mm:ss

# í˜ì´ì§€ ì„¤ì •
per_page: 10
pagination_dir: page

# í”ŒëŸ¬ê·¸ì¸
plugins:
  - hexo-generator-feed
  - hexo-generator-sitemap
  - hexo-generator-baidu-sitemap
  - hexo-renderer-marked
  - hexo-renderer-stylus
  - hexo-server
  - hexo-deployer-git
  - hexo-generator-index
  - hexo-generator-category
  - hexo-generator-tag
  - hexo-generator-archive

# ë°°í¬ ì„¤ì •
deploy:
  type: git
  repo: https://github.com/kronenz/kronenz.github.io.git
  branch: main
  message: "Deploy from AI Agent: {{ now('YYYY-MM-DD HH:mm:ss') }}"

# ê²€ìƒ‰ ì„¤ì •
search:
  path: search.xml
  field: post
  content: true
  format: html

# ëŒ“ê¸€ ì‹œìŠ¤í…œ
utterances:
  repo: kronenz/kronenz.github.io
  issue_term: pathname
  theme: github-light
```

## ğŸ”§ 2ë‹¨ê³„: Agent ì‹œìŠ¤í…œ êµ¬í˜„

### 2.1 Content Processor Agent

```python
# agents/content_processor.py
import yaml
import markdown
from datetime import datetime
from pathlib import Path
import frontmatter
import re

class ContentProcessorAgent:
    def __init__(self, config_path="config/agents.yaml"):
        self.config = self.load_config(config_path)
        self.hexo_config = self.load_hexo_config()
        self.templates = self.load_templates()
    
    def process_series(self, series_path):
        """ì‹œë¦¬ì¦ˆ ì „ì²´ ì²˜ë¦¬"""
        series_spec = self.load_series_spec(series_path)
        guide_specs = self.load_guide_specs(series_path)
        
        results = []
        for guide_spec in guide_specs:
            result = self.process_guide(guide_spec, series_spec)
            results.append(result)
        
        return {
            'series_spec': series_spec,
            'guide_results': results,
            'total_guides': len(guide_specs)
        }
    
    def process_guide(self, guide_spec, series_spec):
        """ê°œë³„ ê°€ì´ë“œ ì²˜ë¦¬"""
        try:
            # 1. Markdown ì½˜í…ì¸  ë¡œë“œ
            markdown_content = self.load_markdown_content(guide_spec)
            
            # 2. Markdown ì²˜ë¦¬
            processed_content = self.process_markdown(markdown_content, guide_spec)
            
            # 3. Front-matter ìƒì„±
            front_matter = self.generate_front_matter(guide_spec, series_spec)
            
            # 4. SEO ìµœì í™”
            seo_data = self.optimize_seo(processed_content, guide_spec)
            
            # 5. Hexo í¬ìŠ¤íŠ¸ ìƒì„±
            hexo_post = self.create_hexo_post(front_matter, processed_content, seo_data)
            
            # 6. íŒŒì¼ ì €ì¥
            output_path = self.save_hexo_post(hexo_post, guide_spec, series_spec)
            
            return {
                'success': True,
                'guide_id': guide_spec['id'],
                'output_path': output_path,
                'seo_score': seo_data.get('score', 0),
                'word_count': processed_content.get('word_count', 0),
                'reading_time': processed_content.get('reading_time', 0)
            }
            
        except Exception as e:
            return {
                'success': False,
                'guide_id': guide_spec['id'],
                'error': str(e)
            }
    
    def load_series_spec(self, series_path):
        """ì‹œë¦¬ì¦ˆ spec ë¡œë“œ"""
        spec_file = Path(series_path) / "series-spec.yaml"
        with open(spec_file, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def load_guide_specs(self, series_path):
        """ê°€ì´ë“œ specë“¤ ë¡œë“œ"""
        guides_dir = Path(series_path) / "guides"
        guide_specs = []
        
        if guides_dir.exists():
            for spec_file in guides_dir.glob("*-spec.yaml"):
                with open(spec_file, 'r', encoding='utf-8') as f:
                    guide_spec = yaml.safe_load(f)
                    guide_specs.append(guide_spec)
        
        return sorted(guide_specs, key=lambda x: x['id'])
    
    def load_markdown_content(self, guide_spec):
        """Markdown ì½˜í…ì¸  ë¡œë“œ"""
        content_source = guide_spec['content']['source']
        content_path = Path(content_source)
        
        if not content_path.exists():
            raise FileNotFoundError(f"Content file not found: {content_source}")
        
        with open(content_path, 'r', encoding='utf-8') as f:
            return f.read()
    
    def process_markdown(self, content, guide_spec):
        """Markdown ì½˜í…ì¸  ì²˜ë¦¬"""
        # ì½”ë“œ í•˜ì´ë¼ì´íŒ… ì„¤ì •
        md = markdown.Markdown(extensions=[
            'codehilite',
            'tables',
            'toc',
            'fenced_code',
            'attr_list',
            'def_list',
            'footnotes',
            'md_in_html'
        ])
        
        # Markdown ë³€í™˜
        html_content = md.convert(content)
        
        # TOC ìƒì„±
        toc = md.toc
        
        # ì´ë¯¸ì§€ ê²½ë¡œ ìµœì í™”
        html_content = self.optimize_image_paths(html_content, guide_spec)
        
        # ë‚´ë¶€ ë§í¬ ìµœì í™”
        html_content = self.optimize_internal_links(html_content, guide_spec)
        
        return {
            'content': html_content,
            'toc': toc,
            'word_count': len(content.split()),
            'reading_time': self.calculate_reading_time(content)
        }
    
    def generate_front_matter(self, guide_spec, series_spec):
        """Hexo front-matter ìƒì„±"""
        front_matter = {
            'title': guide_spec['title'],
            'date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'categories': [series_spec['metadata']['category']],
            'tags': guide_spec.get('publishing', {}).get('blog', {}).get('seo', {}).get('tags', []),
            'permalink': f"/{series_spec['id']}/{guide_spec['id']}/",
            'excerpt': self.generate_excerpt(guide_spec),
            'toc': True,
            'mathjax': True,
            'comments': True
        }
        
        # ì‹œë¦¬ì¦ˆ ì •ë³´ ì¶”ê°€
        front_matter['series'] = {
            'id': series_spec['id'],
            'title': series_spec['title'],
            'position': self.get_guide_position(guide_spec, series_spec)
        }
        
        # SEO ë©”íƒ€ë°ì´í„° ì¶”ê°€
        seo_config = guide_spec.get('publishing', {}).get('blog', {}).get('seo', {})
        if seo_config:
            front_matter['seo'] = {
                'focus_keyword': seo_config.get('focus_keyword'),
                'meta_description': seo_config.get('meta_description'),
                'reading_time': seo_config.get('reading_time')
            }
        
        return front_matter
    
    def optimize_seo(self, content, guide_spec):
        """SEO ìµœì í™”"""
        seo_config = guide_spec.get('publishing', {}).get('blog', {}).get('seo', {})
        
        # í‚¤ì›Œë“œ ë°€ë„ ë¶„ì„
        focus_keyword = seo_config.get('focus_keyword', '')
        keyword_density = self.calculate_keyword_density(content['content'], focus_keyword)
        
        # ë©”íƒ€ ì„¤ëª… ìƒì„±
        meta_description = seo_config.get('meta_description', '')
        if not meta_description:
            meta_description = self.generate_meta_description(content['content'])
        
        # SEO ì ìˆ˜ ê³„ì‚°
        seo_score = self.calculate_seo_score(content, focus_keyword, keyword_density)
        
        return {
            'focus_keyword': focus_keyword,
            'meta_description': meta_description,
            'keyword_density': keyword_density,
            'score': seo_score,
            'recommendations': self.generate_seo_recommendations(seo_score)
        }
    
    def create_hexo_post(self, front_matter, content, seo_data):
        """Hexo í¬ìŠ¤íŠ¸ ìƒì„±"""
        # Front-matterì™€ ì½˜í…ì¸  ê²°í•©
        post = frontmatter.Post(content['content'])
        post.metadata = front_matter
        
        # SEO ë°ì´í„° ì¶”ê°€
        post.metadata['seo'] = seo_data
        
        return post
    
    def save_hexo_post(self, hexo_post, guide_spec, series_spec):
        """Hexo í¬ìŠ¤íŠ¸ ì €ì¥"""
        # íŒŒì¼ëª… ìƒì„±
        filename = f"{guide_spec['id']}-{self.slugify(guide_spec['title'])}.md"
        
        # ì €ì¥ ê²½ë¡œ
        output_dir = Path("source/_posts") / series_spec['id']
        output_dir.mkdir(parents=True, exist_ok=True)
        output_path = output_dir / filename
        
        # íŒŒì¼ ì €ì¥
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(frontmatter.dumps(hexo_post))
        
        return str(output_path)
    
    def slugify(self, text):
        """í…ìŠ¤íŠ¸ë¥¼ URL ì¹œí™”ì ì¸ ìŠ¬ëŸ¬ê·¸ë¡œ ë³€í™˜"""
        text = re.sub(r'[^\w\s-]', '', text.lower())
        text = re.sub(r'[-\s]+', '-', text)
        return text.strip('-')
    
    def calculate_reading_time(self, content):
        """ì½ê¸° ì‹œê°„ ê³„ì‚° (ë¶„)"""
        word_count = len(content.split())
        return max(1, word_count // 200)  # ë¶„ë‹¹ 200ë‹¨ì–´ë¡œ ê³„ì‚°
    
    def generate_excerpt(self, guide_spec):
        """ìš”ì•½ ìƒì„±"""
        return guide_spec.get('subtitle', '') or guide_spec.get('description', '')
    
    def get_guide_position(self, guide_spec, series_spec):
        """ê°€ì´ë“œ ìˆœì„œ ê³„ì‚°"""
        guides = series_spec.get('structure', {}).get('guides', [])
        for i, guide in enumerate(guides, 1):
            if guide['id'] == guide_spec['id']:
                return i
        return 0
```

### 2.2 SEO Optimizer Agent

```python
# agents/seo_optimizer.py
import re
from collections import Counter
import nltk
from textstat import flesch_reading_ease

class SEOOptimizerAgent:
    def __init__(self, config_path="config/seo.yaml"):
        self.config = self.load_config(config_path)
        self.stop_words = self.load_stop_words()
    
    def optimize_content(self, content, guide_spec):
        """ì½˜í…ì¸  SEO ìµœì í™”"""
        try:
            # 1. í‚¤ì›Œë“œ ë¶„ì„
            keywords = self.analyze_keywords(content)
            
            # 2. ì½˜í…ì¸  êµ¬ì¡° ìµœì í™”
            optimized_content = self.optimize_structure(content, keywords)
            
            # 3. ë©”íƒ€ë°ì´í„° ìµœì í™”
            meta_data = self.optimize_metadata(guide_spec, keywords)
            
            # 4. ë‚´ë¶€ ë§í¬ ìµœì í™”
            internal_links = self.optimize_internal_links(content, guide_spec)
            
            # 5. SEO ì ìˆ˜ ê³„ì‚°
            seo_score = self.calculate_seo_score(optimized_content, meta_data)
            
            return {
                'success': True,
                'optimized_content': optimized_content,
                'meta_data': meta_data,
                'keywords': keywords,
                'internal_links': internal_links,
                'seo_score': seo_score
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def analyze_keywords(self, content):
        """í‚¤ì›Œë“œ ë¶„ì„"""
        # í…ìŠ¤íŠ¸ì—ì„œ HTML íƒœê·¸ ì œê±°
        text = re.sub(r'<[^>]+>', '', content)
        
        # ë‹¨ì–´ ì¶”ì¶œ ë° ì •ê·œí™”
        words = re.findall(r'\b\w+\b', text.lower())
        
        # ë¶ˆìš©ì–´ ì œê±°
        filtered_words = [word for word in words if word not in self.stop_words and len(word) > 3]
        
        # ë¹ˆë„ ê³„ì‚°
        word_freq = Counter(filtered_words)
        
        # í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚°
        keywords = []
        for word, freq in word_freq.most_common(20):
            score = self.calculate_keyword_score(word, freq, len(filtered_words))
            keywords.append({
                'word': word,
                'frequency': freq,
                'density': freq / len(filtered_words) * 100,
                'score': score
            })
        
        return keywords
    
    def calculate_keyword_score(self, word, frequency, total_words):
        """í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚°"""
        # ë¹ˆë„ ê¸°ë°˜ ì ìˆ˜
        freq_score = (frequency / total_words) * 100
        
        # ê¸¸ì´ ê¸°ë°˜ ì ìˆ˜ (ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ ë‹¨ì–´ëŠ” ë‚®ì€ ì ìˆ˜)
        length_score = 1.0
        if len(word) < 4:
            length_score = 0.5
        elif len(word) > 15:
            length_score = 0.7
        
        # ìµœì¢… ì ìˆ˜
        return freq_score * length_score
    
    def optimize_structure(self, content, keywords):
        """ì½˜í…ì¸  êµ¬ì¡° ìµœì í™”"""
        # ì£¼ìš” í‚¤ì›Œë“œë¥¼ í—¤ë”©ì— í¬í•¨
        primary_keyword = keywords[0]['word'] if keywords else ''
        
        # H1 íƒœê·¸ ìµœì í™”
        content = self.optimize_h1_tag(content, primary_keyword)
        
        # H2, H3 íƒœê·¸ ìµœì í™”
        content = self.optimize_heading_tags(content, keywords)
        
        return content
    
    def optimize_h1_tag(self, content, primary_keyword):
        """H1 íƒœê·¸ ìµœì í™”"""
        if not primary_keyword:
            return content
        
        # H1 íƒœê·¸ì— í‚¤ì›Œë“œ í¬í•¨ í™•ì¸
        h1_pattern = r'<h1[^>]*>(.*?)</h1>'
        if re.search(h1_pattern, content):
            # ê¸°ì¡´ H1 íƒœê·¸ì— í‚¤ì›Œë“œ ì¶”ê°€
            content = re.sub(
                h1_pattern,
                lambda m: f'<h1>{primary_keyword} - {m.group(1)}</h1>',
                content
            )
        else:
            # H1 íƒœê·¸ê°€ ì—†ìœ¼ë©´ ì¶”ê°€
            content = f'<h1>{primary_keyword}</h1>\n\n{content}'
        
        return content
    
    def calculate_seo_score(self, content, meta_data):
        """SEO ì ìˆ˜ ê³„ì‚°"""
        score = 0
        
        # ì œëª© ìµœì í™” (20ì )
        title_score = self.evaluate_title(meta_data.get('title', ''))
        score += title_score * 0.2
        
        # ë©”íƒ€ ì„¤ëª… ìµœì í™” (15ì )
        description_score = self.evaluate_meta_description(meta_data.get('description', ''))
        score += description_score * 0.15
        
        # í‚¤ì›Œë“œ ë°€ë„ (15ì )
        keyword_density_score = self.evaluate_keyword_density(content)
        score += keyword_density_score * 0.15
        
        # í—¤ë”© êµ¬ì¡° (10ì )
        heading_score = self.evaluate_heading_structure(content)
        score += heading_score * 0.1
        
        # ë‚´ë¶€ ë§í¬ (10ì )
        internal_link_score = self.evaluate_internal_links(content)
        score += internal_link_score * 0.1
        
        # ì´ë¯¸ì§€ ìµœì í™” (10ì )
        image_score = self.evaluate_images(content)
        score += image_score * 0.1
        
        # ê°€ë…ì„± (10ì )
        readability_score = self.evaluate_readability(content)
        score += readability_score * 0.1
        
        # ì½˜í…ì¸  ê¸¸ì´ (10ì )
        length_score = self.evaluate_content_length(content)
        score += length_score * 0.1
        
        return min(score, 100)  # ìµœëŒ€ 100ì 
```

## ğŸš€ 3ë‹¨ê³„: ìë™í™” ìŠ¤í¬ë¦½íŠ¸

### 3.1 Spec ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸

```python
# scripts/process_specs.py
#!/usr/bin/env python3
import argparse
import sys
from pathlib import Path
import yaml
import json
from datetime import datetime

# Agent import
sys.path.append(str(Path(__file__).parent.parent))
from agents.content_processor import ContentProcessorAgent
from agents.seo_optimizer import SEOOptimizerAgent

def main():
    parser = argparse.ArgumentParser(description='Process specs and generate blog posts')
    parser.add_argument('--input', required=True, help='Input specs directory')
    parser.add_argument('--output', required=True, help='Output directory')
    parser.add_argument('--series', help='Specific series to process')
    parser.add_argument('--verbose', action='store_true', help='Verbose output')
    
    args = parser.parse_args()
    
    # Agent ì´ˆê¸°í™”
    content_processor = ContentProcessorAgent()
    seo_optimizer = SEOOptimizerAgent()
    
    # Spec ë””ë ‰í† ë¦¬ ìŠ¤ìº”
    specs_dir = Path(args.input)
    series_dirs = [d for d in specs_dir.glob('series-*') if d.is_dir()]
    
    if args.series:
        series_dirs = [d for d in series_dirs if d.name == args.series]
    
    total_processed = 0
    total_errors = 0
    
    for series_dir in series_dirs:
        print(f"Processing series: {series_dir.name}")
        
        try:
            # ì‹œë¦¬ì¦ˆ ì²˜ë¦¬
            result = content_processor.process_series(series_dir)
            
            if result['total_guides'] > 0:
                print(f"  âœ“ Processed {result['total_guides']} guides")
                total_processed += result['total_guides']
                
                # SEO ìµœì í™”
                for guide_result in result['guide_results']:
                    if guide_result['success']:
                        seo_result = seo_optimizer.optimize_content(
                            guide_result, result['series_spec']
                        )
                        if seo_result['success']:
                            print(f"    âœ“ SEO optimized: {guide_result['guide_id']}")
                        else:
                            print(f"    âœ— SEO optimization failed: {guide_result['guide_id']}")
                            total_errors += 1
                    else:
                        print(f"    âœ— Failed: {guide_result['guide_id']} - {guide_result['error']}")
                        total_errors += 1
            else:
                print(f"  âš  No guides found in {series_dir.name}")
                
        except Exception as e:
            print(f"  âœ— Error processing {series_dir.name}: {e}")
            total_errors += 1
    
    # ê²°ê³¼ ìš”ì•½
    print(f"\nProcessing complete:")
    print(f"  Total guides processed: {total_processed}")
    print(f"  Total errors: {total_errors}")
    print(f"  Success rate: {((total_processed - total_errors) / total_processed * 100):.1f}%" if total_processed > 0 else "N/A")

if __name__ == "__main__":
    main()
```

### 3.2 ë¸”ë¡œê·¸ ìƒì„± ìŠ¤í¬ë¦½íŠ¸

```python
# scripts/generate_blog_posts.py
#!/usr/bin/env python3
import argparse
import sys
from pathlib import Path
import yaml
import json
from datetime import datetime

def main():
    parser = argparse.ArgumentParser(description='Generate blog posts from processed specs')
    parser.add_argument('--input', required=True, help='Input posts directory')
    parser.add_argument('--output', required=True, help='Output directory')
    parser.add_argument('--template', help='Template to use')
    
    args = parser.parse_args()
    
    input_dir = Path(args.input)
    output_dir = Path(args.output)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ì‹œë¦¬ì¦ˆ ë°ì´í„° ìƒì„±
    series_data = generate_series_data(input_dir)
    
    # ì‹œë¦¬ì¦ˆ ë°ì´í„° íŒŒì¼ ì €ì¥
    with open(output_dir / '_data' / 'series.yml', 'w', encoding='utf-8') as f:
        yaml.dump(series_data, f, allow_unicode=True, default_flow_style=False)
    
    # ì¸ë±ìŠ¤ í˜ì´ì§€ ìƒì„±
    generate_index_page(series_data, output_dir)
    
    # ì‹œë¦¬ì¦ˆ í˜ì´ì§€ ìƒì„±
    generate_series_pages(series_data, output_dir)
    
    print(f"Blog generation complete. Output: {output_dir}")

def generate_series_data(input_dir):
    """ì‹œë¦¬ì¦ˆ ë°ì´í„° ìƒì„±"""
    series_data = {}
    
    for series_dir in input_dir.glob('series-*'):
        if series_dir.is_dir():
            series_id = series_dir.name
            series_spec_file = series_dir / 'series-spec.yaml'
            
            if series_spec_file.exists():
                with open(series_spec_file, 'r', encoding='utf-8') as f:
                    series_spec = yaml.safe_load(f)
                
                # í¬ìŠ¤íŠ¸ ëª©ë¡ ìƒì„±
                posts = []
                for post_file in series_dir.glob('*.md'):
                    if post_file.name != 'series-spec.yaml':
                        posts.append({
                            'title': post_file.stem,
                            'path': str(post_file.relative_to(input_dir)),
                            'date': post_file.stat().st_mtime
                        })
                
                series_data[series_id] = {
                    'id': series_id,
                    'title': series_spec['series']['title'],
                    'subtitle': series_spec['series']['subtitle'],
                    'description': series_spec['series']['description'],
                    'category': series_spec['series']['metadata']['category'],
                    'tags': series_spec['series']['metadata']['tags'],
                    'posts': sorted(posts, key=lambda x: x['date'])
                }
    
    return series_data

def generate_index_page(series_data, output_dir):
    """ì¸ë±ìŠ¤ í˜ì´ì§€ ìƒì„±"""
    index_content = f"""---
title: AI ê°€ì´ë“œ ì‹œë¦¬ì¦ˆ
layout: page
---

# AI ê°€ì´ë“œ ì‹œë¦¬ì¦ˆ

AIì™€ ìë™í™”ë¥¼ í†µí•´ 100ë°° ìƒì‚°ì„±ì„ ë‹¬ì„±í•˜ëŠ” ì™„ì „í•œ ê°€ì´ë“œ ëª¨ìŒì…ë‹ˆë‹¤.

## ì‹œë¦¬ì¦ˆ ëª©ë¡

"""
    
    for series_id, series_info in series_data.items():
        index_content += f"""
### [{series_info['title']}](/{series_id}/)

{series_info['description']}

- **ì¹´í…Œê³ ë¦¬**: {series_info['category']}
- **íƒœê·¸**: {', '.join(series_info['tags'])}
- **ê°€ì´ë“œ ìˆ˜**: {len(series_info['posts'])}ê°œ

"""
    
    with open(output_dir / 'index.md', 'w', encoding='utf-8') as f:
        f.write(index_content)

def generate_series_pages(series_data, output_dir):
    """ì‹œë¦¬ì¦ˆ í˜ì´ì§€ ìƒì„±"""
    for series_id, series_info in series_data.items():
        series_page_content = f"""---
title: {series_info['title']}
layout: page
---

# {series_info['title']}

{series_info['subtitle']}

{series_info['description']}

## ê°€ì´ë“œ ëª©ë¡

"""
        
        for i, post in enumerate(series_info['posts'], 1):
            series_page_content += f"{i}. [{post['title']}](/{series_id}/{post['title']}/)\n"
        
        series_dir = output_dir / series_id
        series_dir.mkdir(exist_ok=True)
        
        with open(series_dir / 'index.md', 'w', encoding='utf-8') as f:
            f.write(series_page_content)

if __name__ == "__main__":
    main()
```

## ğŸ”„ 4ë‹¨ê³„: GitHub Actions ì›Œí¬í”Œë¡œìš°

### 4.1 ìë™ ì¶œíŒ ì›Œí¬í”Œë¡œìš°

```yaml
# .github/workflows/publish-blog.yml
name: Publish Blog

on:
  push:
    branches: [main]
    paths: ['specs/**/*.yaml', 'specs/**/*.md']
  schedule:
    - cron: '0 2 * * *'  # ë§¤ì¼ ì˜¤ì „ 2ì‹œ ì‹¤í–‰
  workflow_dispatch:

jobs:
  process-specs:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          cache: 'npm'
      
      - name: Setup Python
        uses: actions/setup-python@v3
        with:
          python-version: '3.9'
          cache: 'pip'
      
      - name: Install Node.js dependencies
        run: |
          cd publishing-system
          npm install
      
      - name: Install Python dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Process Specs
        run: |
          python scripts/process_specs.py --input specs/ --output publishing-system/source/_posts/
      
      - name: Generate Blog Posts
        run: |
          cd publishing-system
          python scripts/generate_blog_posts.py --input source/_posts/ --output source/
      
      - name: Build Hexo Site
        run: |
          cd publishing-system
          npx hexo clean
          npx hexo generate
      
      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./publishing-system/public
          cname: kronenz.github.io
```

## ğŸ“Š 5ë‹¨ê³„: ëª¨ë‹ˆí„°ë§ ë° ë¶„ì„

### 5.1 ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

```python
# monitoring/performance_monitor.py
import time
import psutil
import json
from datetime import datetime
from pathlib import Path

class PerformanceMonitor:
    def __init__(self, log_file="logs/performance.json"):
        self.log_file = Path(log_file)
        self.log_file.parent.mkdir(exist_ok=True)
        self.metrics = {
            'processing_times': [],
            'memory_usage': [],
            'cpu_usage': [],
            'error_count': 0,
            'success_count': 0
        }
    
    def start_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        self.start_time = time.time()
        self.start_memory = psutil.virtual_memory().used
        self.start_cpu = psutil.cpu_percent()
    
    def end_monitoring(self, success=True):
        """ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ"""
        end_time = time.time()
        processing_time = end_time - self.start_time
        
        # ë©”íŠ¸ë¦­ ê¸°ë¡
        self.metrics['processing_times'].append(processing_time)
        self.metrics['memory_usage'].append(psutil.virtual_memory().used)
        self.metrics['cpu_usage'].append(psutil.cpu_percent())
        
        if success:
            self.metrics['success_count'] += 1
        else:
            self.metrics['error_count'] += 1
        
        # ë¡œê·¸ ì €ì¥
        self.save_metrics()
    
    def save_metrics(self):
        """ë©”íŠ¸ë¦­ ì €ì¥"""
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'metrics': self.metrics
        }
        
        # ê¸°ì¡´ ë¡œê·¸ ë¡œë“œ
        if self.log_file.exists():
            with open(self.log_file, 'r', encoding='utf-8') as f:
                logs = json.load(f)
        else:
            logs = []
        
        logs.append(log_entry)
        
        # ë¡œê·¸ ì €ì¥
        with open(self.log_file, 'w', encoding='utf-8') as f:
            json.dump(logs, f, indent=2, ensure_ascii=False)
    
    def get_performance_summary(self):
        """ì„±ëŠ¥ ìš”ì•½ ë°˜í™˜"""
        if not self.metrics['processing_times']:
            return None
        
        return {
            'total_processed': self.metrics['success_count'] + self.metrics['error_count'],
            'success_rate': self.metrics['success_count'] / (self.metrics['success_count'] + self.metrics['error_count']) * 100,
            'average_processing_time': sum(self.metrics['processing_times']) / len(self.metrics['processing_times']),
            'average_memory_usage': sum(self.metrics['memory_usage']) / len(self.metrics['memory_usage']),
            'average_cpu_usage': sum(self.metrics['cpu_usage']) / len(self.metrics['cpu_usage'])
        }
```

## ğŸ¯ ì‹¤í–‰ ë°©ë²•

### 1. ì´ˆê¸° ì„¤ì •

```bash
# 1. Hexo ì‚¬ì´íŠ¸ ì´ˆê¸°í™”
npx hexo init publishing-system
cd publishing-system

# 2. ì˜ì¡´ì„± ì„¤ì¹˜
npm install
pip install -r requirements.txt

# 3. ì„¤ì • íŒŒì¼ ë³µì‚¬
cp ../publishing/_config.yml .
cp -r ../publishing/source/* source/
cp -r ../publishing/specs/* specs/
cp -r ../publishing/agents/* agents/
cp -r ../publishing/scripts/* scripts/
```

### 2. Spec ì²˜ë¦¬

```bash
# ëª¨ë“  ì‹œë¦¬ì¦ˆ ì²˜ë¦¬
python scripts/process_specs.py --input specs/ --output source/_posts/

# íŠ¹ì • ì‹œë¦¬ì¦ˆë§Œ ì²˜ë¦¬
python scripts/process_specs.py --input specs/ --output source/_posts/ --series series-5
```

### 3. ë¸”ë¡œê·¸ ìƒì„±

```bash
# ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìƒì„±
python scripts/generate_blog_posts.py --input source/_posts/ --output source/

# Hexo ì‚¬ì´íŠ¸ ë¹Œë“œ
npx hexo clean
npx hexo generate

# ë¡œì»¬ ì„œë²„ ì‹¤í–‰
npx hexo server
```

### 4. GitHub Pages ë°°í¬

```bash
# GitHub Pagesì— ë°°í¬
npx hexo deploy
```

## ğŸ“š ë‹¤ìŒ ë‹¨ê³„

ì´ ì„¤ì •ì„ ì™„ë£Œí•œ í›„ ë‹¤ìŒ ì‘ì—…ì„ ì§„í–‰í•©ë‹ˆë‹¤:

1. **í…Œë§ˆ ì»¤ìŠ¤í„°ë§ˆì´ì§•**: ê°€ì´ë“œ ì‹œë¦¬ì¦ˆì— ìµœì í™”ëœ í…Œë§ˆ ê°œë°œ
2. **ê²€ìƒ‰ ê¸°ëŠ¥**: Algolia ë˜ëŠ” ë‹¤ë¥¸ ê²€ìƒ‰ ì„œë¹„ìŠ¤ í†µí•©
3. **ëŒ“ê¸€ ì‹œìŠ¤í…œ**: Utterances ë˜ëŠ” Disqus í†µí•©
4. **ë¶„ì„ ë„êµ¬**: Google Analytics, Google Search Console í†µí•©
5. **ì„±ëŠ¥ ìµœì í™”**: ì´ë¯¸ì§€ ìµœì í™”, CDN ì„¤ì •

---

**"Hexo í†µí•© ì„¤ì • ê°€ì´ë“œ"** - ê¸°ì¡´ ê°€ì´ë“œ ì‹œë¦¬ì¦ˆë¥¼ Hexo ê¸°ë°˜ GitHub Pages ë¸”ë¡œê·¸ë¡œ ì™„ì „ ìë™í™”í•˜ì—¬ ì¶œíŒí•˜ëŠ” ì‹œìŠ¤í…œì„ êµ¬ì¶•í•©ë‹ˆë‹¤!
